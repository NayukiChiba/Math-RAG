"""
å¯¹æ¯”å®éªŒè„šæœ¬ï¼šRAG vs æ— æ£€ç´¢

åŠŸèƒ½ï¼š
1. åœ¨ç›¸åŒæµ‹è¯•é›†ä¸Šè¿è¡Œå¤šç»„å¯¹æ¯”å®éªŒ
2. å®éªŒç»„ï¼šbaseline-noragã€baseline-bm25ã€baseline-vectorã€exp-hybrid
3. è®°å½•æ£€ç´¢æŒ‡æ ‡ï¼ˆRecall@5, MRRï¼‰å’Œç”ŸæˆæŒ‡æ ‡ï¼ˆæœ¯è¯­å‘½ä¸­ç‡ã€æ¥æºå¼•ç”¨ç‡ï¼‰
4. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šå’Œå›¾è¡¨

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/runExperiments.py
    python scripts/runExperiments.py --groups norag bm25 vector hybrid
    python scripts/runExperiments.py --limit 10  # é™åˆ¶æŸ¥è¯¢æ•°é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰
"""

import os

# è§£å†³ OpenMP åº“å†²çªé—®é¢˜ï¼ˆnumpy/torch/faiss åŒæ—¶ä½¿ç”¨æ—¶ï¼‰
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

import argparse
import json
import sys
import time
from pathlib import Path
from typing import Any, Literal

# è·¯å¾„è°ƒæ•´
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

import config

# å®éªŒç»„ç±»å‹
ExperimentGroup = Literal["norag", "bm25", "vector", "hybrid"]


class ExperimentRunner:
    """å¯¹æ¯”å®éªŒè¿è¡Œå™¨"""

    def __init__(
        self,
        queryFile: str | None = None,
        outputDir: str | None = None,
        logDir: str | None = None,
    ):
        """
        åˆå§‹åŒ–å®éªŒè¿è¡Œå™¨

        Args:
            queryFile: æµ‹è¯•æŸ¥è¯¢é›†æ–‡ä»¶è·¯å¾„
            outputDir: è¾“å‡ºç›®å½•
            logDir: æ—¥å¿—ç›®å½•
        """
        self.queryFile = queryFile or os.path.join(
            config.PROJECT_ROOT, "data", "evaluation", "queries.jsonl"
        )
        self.outputDir = outputDir or os.path.join(
            config.PROJECT_ROOT, "outputs", "reports"
        )
        self.logDir = logDir or os.path.join(config.PROJECT_ROOT, "outputs", "logs")

        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.outputDir, exist_ok=True)
        os.makedirs(self.logDir, exist_ok=True)

        # å»¶è¿ŸåŠ è½½
        self._qwen = None
        self._retrievers = {}
        self._queries = None
        self._goldMap = None

    def _loadQueries(self) -> list[dict[str, Any]]:
        """åŠ è½½æµ‹è¯•æŸ¥è¯¢é›†"""
        if self._queries is not None:
            return self._queries

        self._queries = []
        self._goldMap = {}

        with open(self.queryFile, encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    query = json.loads(line)
                    # æ ¡éªŒå¿…éœ€å­—æ®µ
                    if "query" not in query:
                        print(f"âš ï¸ è·³è¿‡ç¼ºå°‘ query å­—æ®µçš„è¡Œ: {line[:50]}...")
                        continue
                    self._queries.append(query)
                    self._goldMap[query["query"]] = query
                except json.JSONDecodeError:
                    continue

        print(f"âœ… åŠ è½½äº† {len(self._queries)} æ¡æµ‹è¯•æŸ¥è¯¢")
        return self._queries

    def _initQwen(self):
        """åˆå§‹åŒ– Qwen æ¨ç†å®ä¾‹"""
        if self._qwen is None:
            print("ğŸ”§ åˆå§‹åŒ– Qwen æ¨ç†...")
            from generation.qwenInference import QwenInference

            self._qwen = QwenInference()
        return self._qwen

    def _initRetriever(self, strategy: str):
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        if strategy in self._retrievers:
            return self._retrievers[strategy]

        retrievalDir = os.path.join(config.PROCESSED_DIR, "retrieval")
        corpusFile = os.path.join(retrievalDir, "corpus.jsonl")
        bm25IndexFile = os.path.join(retrievalDir, "bm25_index.pkl")
        vectorIndexFile = os.path.join(retrievalDir, "vector_index.faiss")
        vectorEmbeddingFile = os.path.join(retrievalDir, "vector_embeddings.npz")

        print(f"ğŸ”§ åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆç­–ç•¥: {strategy}ï¼‰...")

        if strategy == "bm25":
            from retrieval.retrievalBM25 import BM25Retriever

            retriever = BM25Retriever(corpusFile, bm25IndexFile)
            if not retriever.loadIndex():
                retriever.buildIndex()
                retriever.saveIndex()

        elif strategy == "vector":
            from retrieval.retrievalVector import VectorRetriever

            retriever = VectorRetriever(
                corpusFile,
                indexFile=vectorIndexFile,
                embeddingFile=vectorEmbeddingFile,
            )
            if not retriever.loadIndex():
                retriever.buildIndex()
                retriever.saveIndex()

        elif strategy == "hybrid":
            from retrieval.retrievalHybrid import HybridRetriever

            retriever = HybridRetriever(
                corpusFile,
                bm25IndexFile,
                vectorIndexFile,
                vectorEmbeddingFile,
            )

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ£€ç´¢ç­–ç•¥: {strategy}")

        self._retrievers[strategy] = retriever
        print("âœ… æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
        return retriever

    def _loadCorpus(self) -> dict[str, dict[str, Any]]:
        """åŠ è½½è¯­æ–™åº“"""
        corpusFile = os.path.join(config.PROCESSED_DIR, "retrieval", "corpus.jsonl")
        corpus = {}
        if os.path.exists(corpusFile):
            with open(corpusFile, encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:
                        try:
                            doc = json.loads(line)
                            docId = doc.get("doc_id")
                            if docId:
                                corpus[docId] = doc
                        except json.JSONDecodeError:
                            continue
        return corpus

    def _enrichResults(
        self, results: list[dict], corpus: dict[str, dict]
    ) -> list[dict[str, Any]]:
        """è¡¥å……æ£€ç´¢ç»“æœçš„å®Œæ•´ä¿¡æ¯"""
        enriched = []
        for r in results:
            docId = r.get("doc_id")
            if docId and docId in corpus:
                doc = corpus[docId]
                enriched.append(
                    {
                        "rank": r.get("rank"),
                        "doc_id": docId,
                        "term": doc.get("term", r.get("term", "")),
                        "subject": doc.get("subject", r.get("subject", "")),
                        "text": doc.get("text", ""),
                        "source": doc.get("source", r.get("source", "")),
                        "page": doc.get("page", r.get("page")),
                        "score": r.get("score", 0.0),
                    }
                )
            else:
                enriched.append(r)
        return enriched

    # ---- æ£€ç´¢æŒ‡æ ‡è®¡ç®— ----

    def _calculateRecallAtK(
        self, results: list[dict], relevantTerms: list[str], k: int
    ) -> float:
        """è®¡ç®— Recall@K"""
        if not relevantTerms:
            return 0.0
        topkTerms = {r.get("term", "") for r in results[:k]}
        found = sum(1 for term in relevantTerms if term in topkTerms)
        return found / len(relevantTerms)

    def _calculateMRR(self, results: list[dict], relevantTerms: list[str]) -> float:
        """è®¡ç®— MRR"""
        for rank, result in enumerate(results, 1):
            if result.get("term", "") in relevantTerms:
                return 1.0 / rank
        return 0.0

    # ---- ç”ŸæˆæŒ‡æ ‡è®¡ç®— ----

    def _calculateTermHitRate(
        self, answer: str, relevantTerms: list[str]
    ) -> dict[str, Any]:
        """è®¡ç®—æœ¯è¯­å‘½ä¸­ç‡"""
        import re

        if not relevantTerms:
            return {"hit_count": 0, "total": 0, "rate": 0.0}

        hitCount = 0
        answerLower = answer.lower()

        for term in relevantTerms:
            termLower = term.lower()
            isEnglishLike = re.search(r"[A-Za-z]", termLower) is not None

            if isEnglishLike:
                pattern = r"\b" + re.escape(termLower) + r"\b"
                if re.search(pattern, answerLower):
                    hitCount += 1
            else:
                if termLower in answerLower:
                    hitCount += 1

        return {
            "hit_count": hitCount,
            "total": len(relevantTerms),
            "rate": hitCount / len(relevantTerms),
        }

    def _calculateSourceCitationRate(
        self, answer: str, sources: list[dict]
    ) -> dict[str, Any]:
        """
        è®¡ç®—æ¥æºå¼•ç”¨ç‡

        æ£€æµ‹é€»è¾‘ï¼š
        1. å®Œæ•´ä¹¦ååŒ¹é…ï¼ˆå¦‚"æ•°å­¦åˆ†æ(ç¬¬5ç‰ˆ)ä¸Š(åä¸œå¸ˆèŒƒå¤§å­¦æ•°å­¦ç³»)"ï¼‰
        2. ç®€åŒ–ä¹¦ååŒ¹é…ï¼ˆå¦‚"æ•°å­¦åˆ†æ"ï¼‰
        3. ã€ä¹¦åã€‘æ ¼å¼åŒ¹é…
        4. é¡µç åŒ¹é…ï¼ˆç¬¬Xé¡µã€p.X ç­‰ï¼‰
        """
        import re

        if not sources:
            return {"cited_count": 0, "total": 0, "rate": 0.0}

        seenSources = set()
        uniqueSources = []
        for s in sources:
            sourceName = s.get("source", "")
            if sourceName and sourceName not in seenSources:
                seenSources.add(sourceName)
                uniqueSources.append(s)

        citedCount = 0
        for s in uniqueSources:
            sourceName = s.get("source", "")
            page = s.get("page")

            if not sourceName:
                continue

            cited = False

            # 1. å®Œæ•´ä¹¦ååŒ¹é…
            if sourceName in answer:
                cited = True

            # 2. ç®€åŒ–ä¹¦ååŒ¹é…ï¼ˆæå–æ‹¬å·å‰çš„ä¸»æ ‡é¢˜ï¼‰
            if not cited:
                # "æ•°å­¦åˆ†æ(ç¬¬5ç‰ˆ)ä¸Š(åä¸œå¸ˆèŒƒå¤§å­¦æ•°å­¦ç³»)" -> "æ•°å­¦åˆ†æ"
                shortName = re.split(r"[(\ï¼ˆ]", sourceName)[0].strip()
                if shortName and len(shortName) >= 2 and shortName in answer:
                    cited = True

            # 3. ã€ä¹¦åã€‘æ ¼å¼åŒ¹é…
            if not cited:
                # æ£€æŸ¥ã€æ•°å­¦åˆ†æ...ã€‘æ ¼å¼
                bracketPattern = r"ã€[^ã€‘]*" + re.escape(shortName) + r"[^ã€‘]*ã€‘"
                if re.search(bracketPattern, answer):
                    cited = True

            # 4. é¡µç åŒ¹é…ï¼ˆä½œä¸ºè¾…åŠ©è¯æ®ï¼‰
            if not cited and page:
                pagePatterns = [
                    f"ç¬¬{page}é¡µ",
                    f"ç¬¬ {page} é¡µ",
                    f"p\\.?{page}",
                    f"Page {page}",
                ]
                for pattern in pagePatterns:
                    if re.search(pattern, answer, re.IGNORECASE):
                        cited = True
                        break

            if cited:
                citedCount += 1

        return {
            "cited_count": citedCount,
            "total": len(uniqueSources),
            "rate": citedCount / len(uniqueSources) if uniqueSources else 0.0,
        }

    # ---- å®éªŒè¿è¡Œ ----

    def runNoRagExperiment(
        self, queries: list[dict], showProgress: bool = True
    ) -> dict[str, Any]:
        """
        è¿è¡Œæ— æ£€ç´¢ baseline å®éªŒ

        ç›´æ¥ä½¿ç”¨ Qwen å›ç­”ï¼Œä¸æ³¨å…¥ä»»ä½•ä¸Šä¸‹æ–‡
        """
        print("\n" + "=" * 60)
        print("ğŸ“Š å®éªŒç»„: baseline-noragï¼ˆæ— æ£€ç´¢ï¼‰")
        print("=" * 60)

        qwen = self._initQwen()
        results = []
        termHitRates = []
        sourceCitationRates = []

        for i, q in enumerate(queries, 1):
            queryText = q["query"]
            relevantTerms = q.get("relevant_terms", [])

            if showProgress:
                print(f"  å¤„ç† {i}/{len(queries)}: {queryText[:30]}...")

            startTime = time.time()

            # æ— æ£€ç´¢ï¼šç›´æ¥æ„å»ºç®€å• prompt
            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°å­¦æ•™å­¦åŠ©æ‰‹ã€‚è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„æ•°å­¦é—®é¢˜ã€‚",
                },
                {"role": "user", "content": queryText},
            ]

            try:
                answer = qwen.generateFromMessages(messages)
            except Exception as e:
                print(f"    âŒ ç”Ÿæˆå¤±è´¥: {e}")
                answer = f"ç”Ÿæˆå¤±è´¥: {e}"

            latency = int((time.time() - startTime) * 1000)

            # è®¡ç®—ç”ŸæˆæŒ‡æ ‡
            termHit = self._calculateTermHitRate(answer, relevantTerms)
            termHitRates.append(termHit["rate"])

            # æ— æ£€ç´¢æ²¡æœ‰æ¥æº
            sourceCitationRates.append(0.0)

            results.append(
                {
                    "query": queryText,
                    "answer": answer,
                    "retrieved_terms": [],
                    "sources": [],
                    "latency_ms": latency,
                    "term_hit": termHit,
                }
            )

        return {
            "group": "baseline-norag",
            "strategy": None,
            "total_queries": len(queries),
            "retrieval_metrics": {
                "recall@5": 0.0,
                "mrr": 0.0,
            },
            "generation_metrics": {
                "term_hit_rate": sum(termHitRates) / len(termHitRates)
                if termHitRates
                else 0.0,
                "source_citation_rate": 0.0,
            },
            "avg_latency_ms": sum(r["latency_ms"] for r in results) / len(results)
            if results
            else 0,
            "results": results,
        }

    def runRagExperiment(
        self,
        queries: list[dict],
        strategy: str,
        topK: int = 5,
        showProgress: bool = True,
    ) -> dict[str, Any]:
        """
        è¿è¡Œ RAG å®éªŒ

        Args:
            queries: æŸ¥è¯¢åˆ—è¡¨
            strategy: æ£€ç´¢ç­–ç•¥ï¼ˆbm25/vector/hybridï¼‰
            topK: æ£€ç´¢è¿”å›æ•°é‡
            showProgress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        """
        groupName = f"baseline-{strategy}" if strategy != "hybrid" else "exp-hybrid"
        print("\n" + "=" * 60)
        print(f"ğŸ“Š å®éªŒç»„: {groupName}ï¼ˆ{strategy} æ£€ç´¢ï¼‰")
        print("=" * 60)

        qwen = self._initQwen()
        retriever = self._initRetriever(strategy)
        corpus = self._loadCorpus()

        results = []
        recallAt5List = []
        mrrList = []
        termHitRates = []
        sourceCitationRates = []

        for i, q in enumerate(queries, 1):
            queryText = q["query"]
            relevantTerms = q.get("relevant_terms", [])

            if showProgress:
                print(f"  å¤„ç† {i}/{len(queries)}: {queryText[:30]}...")

            startTime = time.time()

            # æ£€ç´¢
            try:
                if strategy == "hybrid":
                    rawResults = retriever.search(
                        queryText, topK=topK, strategy="weighted", alpha=0.5, beta=0.5
                    )
                else:
                    rawResults = retriever.search(queryText, topK=topK)
                retrievalResults = self._enrichResults(rawResults, corpus)
            except Exception as e:
                print(f"    âŒ æ£€ç´¢å¤±è´¥: {e}")
                retrievalResults = []

            retrievalTime = time.time() - startTime

            # è®¡ç®—æ£€ç´¢æŒ‡æ ‡
            recallAt5 = self._calculateRecallAtK(retrievalResults, relevantTerms, 5)
            mrr = self._calculateMRR(retrievalResults, relevantTerms)
            recallAt5List.append(recallAt5)
            mrrList.append(mrr)

            # ç”Ÿæˆ
            genStartTime = time.time()
            try:
                from generation.promptTemplates import buildMessages

                messages = buildMessages(
                    query=queryText,
                    retrievalResults=retrievalResults if retrievalResults else None,
                )
                answer = qwen.generateFromMessages(messages)
            except Exception as e:
                print(f"    âŒ ç”Ÿæˆå¤±è´¥: {e}")
                answer = f"ç”Ÿæˆå¤±è´¥: {e}"

            generationTime = time.time() - genStartTime
            totalLatency = int((time.time() - startTime) * 1000)

            # è®¡ç®—ç”ŸæˆæŒ‡æ ‡
            termHit = self._calculateTermHitRate(answer, relevantTerms)
            termHitRates.append(termHit["rate"])

            sources = [
                {"source": r.get("source", ""), "page": r.get("page")}
                for r in retrievalResults
                if r.get("source")
            ]
            sourceCitation = self._calculateSourceCitationRate(answer, sources)
            sourceCitationRates.append(sourceCitation["rate"])

            results.append(
                {
                    "query": queryText,
                    "answer": answer,
                    "retrieved_terms": [
                        {"term": r.get("term", ""), "score": r.get("score", 0)}
                        for r in retrievalResults
                    ],
                    "sources": sources,
                    "latency_ms": totalLatency,
                    "retrieval_ms": int(retrievalTime * 1000),
                    "generation_ms": int(generationTime * 1000),
                    "recall@5": recallAt5,
                    "mrr": mrr,
                    "term_hit": termHit,
                    "source_citation": sourceCitation,
                }
            )

        return {
            "group": groupName,
            "strategy": strategy,
            "total_queries": len(queries),
            "retrieval_metrics": {
                "recall@5": sum(recallAt5List) / len(recallAt5List)
                if recallAt5List
                else 0.0,
                "mrr": sum(mrrList) / len(mrrList) if mrrList else 0.0,
            },
            "generation_metrics": {
                "term_hit_rate": sum(termHitRates) / len(termHitRates)
                if termHitRates
                else 0.0,
                "source_citation_rate": sum(sourceCitationRates)
                / len(sourceCitationRates)
                if sourceCitationRates
                else 0.0,
            },
            "avg_latency_ms": sum(r["latency_ms"] for r in results) / len(results)
            if results
            else 0,
            "results": results,
        }

    # ---- æŠ¥å‘Šç”Ÿæˆ ----

    def generateReport(self, experimentResults: list[dict[str, Any]]) -> dict[str, Any]:
        """
        ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

        Args:
            experimentResults: å„å®éªŒç»„ç»“æœåˆ—è¡¨

        Returns:
            å¯¹æ¯”æŠ¥å‘Šå­—å…¸
        """
        report = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_groups": len(experimentResults),
            "groups": [],
            "comparison": {},
        }

        # æ±‡æ€»å„ç»„æŒ‡æ ‡
        for result in experimentResults:
            groupSummary = {
                "group": result["group"],
                "strategy": result["strategy"],
                "total_queries": result["total_queries"],
                "retrieval_metrics": result["retrieval_metrics"],
                "generation_metrics": result["generation_metrics"],
                "avg_latency_ms": result["avg_latency_ms"],
            }
            report["groups"].append(groupSummary)

        # ç”Ÿæˆå¯¹æ¯”åˆ†æ
        if len(experimentResults) >= 2:
            bestTermHit = max(
                experimentResults,
                key=lambda x: x["generation_metrics"]["term_hit_rate"],
            )
            bestRecall = max(
                experimentResults,
                key=lambda x: x["retrieval_metrics"]["recall@5"],
            )

            report["comparison"] = {
                "best_term_hit_rate": {
                    "group": bestTermHit["group"],
                    "value": bestTermHit["generation_metrics"]["term_hit_rate"],
                },
                "best_recall@5": {
                    "group": bestRecall["group"],
                    "value": bestRecall["retrieval_metrics"]["recall@5"],
                },
            }

        return report

    def generateMarkdownTable(self, experimentResults: list[dict[str, Any]]) -> str:
        """
        ç”Ÿæˆå¯å¤åˆ¶å…¥è®ºæ–‡çš„ Markdown è¡¨æ ¼

        Args:
            experimentResults: å„å®éªŒç»„ç»“æœåˆ—è¡¨

        Returns:
            Markdown è¡¨æ ¼å­—ç¬¦ä¸²
        """
        lines = []
        lines.append("## å¯¹æ¯”å®éªŒç»“æœ")
        lines.append("")
        lines.append("### æ£€ç´¢æŒ‡æ ‡å¯¹æ¯”")
        lines.append("")
        lines.append("| å®éªŒç»„ | æ£€ç´¢ç­–ç•¥ | Recall@5 | MRR |")
        lines.append("|--------|----------|----------|-----|")

        for result in experimentResults:
            group = result["group"]
            strategy = result["strategy"] or "-"
            # norag æ²¡æœ‰æ£€ç´¢ï¼Œæ˜¾ç¤º N/A
            if result["strategy"] is None:
                lines.append(f"| {group} | {strategy} | N/A | N/A |")
            else:
                recall = result["retrieval_metrics"]["recall@5"]
                mrr = result["retrieval_metrics"]["mrr"]
                lines.append(f"| {group} | {strategy} | {recall:.4f} | {mrr:.4f} |")

        lines.append("")
        lines.append("### ç”ŸæˆæŒ‡æ ‡å¯¹æ¯”")
        lines.append("")
        lines.append("| å®éªŒç»„ | æœ¯è¯­å‘½ä¸­ç‡ | æ¥æºå¼•ç”¨ç‡ | å¹³å‡å»¶è¿Ÿ(ms) |")
        lines.append("|--------|------------|------------|--------------|")

        for result in experimentResults:
            group = result["group"]
            termHit = result["generation_metrics"]["term_hit_rate"]
            sourceCite = result["generation_metrics"]["source_citation_rate"]
            latency = result["avg_latency_ms"]
            lines.append(
                f"| {group} | {termHit:.4f} | {sourceCite:.4f} | {latency:.0f} |"
            )

        return "\n".join(lines)

    def generateChart(
        self, experimentResults: list[dict[str, Any]], outputPath: str
    ) -> bool:
        """
        ç”Ÿæˆå¯¹æ¯”å›¾è¡¨

        Args:
            experimentResults: å„å®éªŒç»„ç»“æœåˆ—è¡¨
            outputPath: å›¾è¡¨è¾“å‡ºè·¯å¾„

        Returns:
            æ˜¯å¦æˆåŠŸç”Ÿæˆ
        """
        try:
            import matplotlib
            import matplotlib.pyplot as plt

            # è®¾ç½®ä¸­æ–‡å­—ä½“
            matplotlib.rcParams["font.sans-serif"] = ["SimHei", "DejaVu Sans"]
            matplotlib.rcParams["axes.unicode_minus"] = False

            groups = [r["group"] for r in experimentResults]
            # å¯¹äº norag ç»„ï¼ˆstrategy ä¸º Noneï¼‰ï¼Œæ£€ç´¢æŒ‡æ ‡ç”¨ None è¡¨ç¤ºï¼Œå›¾è¡¨ä¸­æ˜¾ç¤º N/A
            recallAt5 = [
                r["retrieval_metrics"]["recall@5"]
                if r.get("strategy") is not None
                else None
                for r in experimentResults
            ]
            mrr = [
                r["retrieval_metrics"]["mrr"] if r.get("strategy") is not None else None
                for r in experimentResults
            ]
            termHitRate = [
                r["generation_metrics"]["term_hit_rate"] for r in experimentResults
            ]
            sourceCiteRate = [
                r["generation_metrics"]["source_citation_rate"]
                for r in experimentResults
            ]

            # åˆ›å»º 2x2 å­å›¾
            fig, axes = plt.subplots(2, 2, figsize=(12, 10))
            fig.suptitle("RAG å¯¹æ¯”å®éªŒç»“æœ", fontsize=14, fontweight="bold")

            # å›¾1: Recall@5ï¼ˆè·³è¿‡ None å€¼ï¼‰
            ax1 = axes[0, 0]
            validRecall = [(g, v) for g, v in zip(groups, recallAt5) if v is not None]
            if validRecall:
                recallGroups, recallVals = zip(*validRecall)
                bars1 = ax1.bar(recallGroups, recallVals, color="steelblue")
                for bar, val in zip(bars1, recallVals):
                    ax1.text(
                        bar.get_x() + bar.get_width() / 2,
                        bar.get_height() + 0.02,
                        f"{val:.3f}",
                        ha="center",
                        fontsize=9,
                    )
            ax1.set_title("Recall@5")
            ax1.set_ylabel("åˆ†æ•°")
            ax1.set_ylim(0, 1)

            # å›¾2: MRRï¼ˆè·³è¿‡ None å€¼ï¼‰
            ax2 = axes[0, 1]
            validMrr = [(g, v) for g, v in zip(groups, mrr) if v is not None]
            if validMrr:
                mrrGroups, mrrVals = zip(*validMrr)
                bars2 = ax2.bar(mrrGroups, mrrVals, color="darkorange")
                for bar, val in zip(bars2, mrrVals):
                    ax2.text(
                        bar.get_x() + bar.get_width() / 2,
                        bar.get_height() + 0.02,
                        f"{val:.3f}",
                        ha="center",
                        fontsize=9,
                    )
            ax2.set_title("MRR")
            ax2.set_ylabel("åˆ†æ•°")
            ax2.set_ylim(0, 1)

            # å›¾3: æœ¯è¯­å‘½ä¸­ç‡
            ax3 = axes[1, 0]
            bars3 = ax3.bar(groups, termHitRate, color="seagreen")
            ax3.set_title("æœ¯è¯­å‘½ä¸­ç‡")
            ax3.set_ylabel("æ¯”ç‡")
            ax3.set_ylim(0, 1)
            for bar, val in zip(bars3, termHitRate):
                ax3.text(
                    bar.get_x() + bar.get_width() / 2,
                    bar.get_height() + 0.02,
                    f"{val:.3f}",
                    ha="center",
                    fontsize=9,
                )

            # å›¾4: æ¥æºå¼•ç”¨ç‡
            ax4 = axes[1, 1]
            bars4 = ax4.bar(groups, sourceCiteRate, color="mediumpurple")
            ax4.set_title("æ¥æºå¼•ç”¨ç‡")
            ax4.set_ylabel("æ¯”ç‡")
            ax4.set_ylim(0, 1)
            for bar, val in zip(bars4, sourceCiteRate):
                ax4.text(
                    bar.get_x() + bar.get_width() / 2,
                    bar.get_height() + 0.02,
                    f"{val:.3f}",
                    ha="center",
                    fontsize=9,
                )

            plt.tight_layout(rect=[0, 0, 1, 0.96])
            plt.savefig(outputPath, dpi=150, bbox_inches="tight")
            plt.close()

            print(f"âœ… å›¾è¡¨å·²ä¿å­˜: {outputPath}")
            return True

        except ImportError:
            print("âš ï¸ matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨ç”Ÿæˆ")
            return False
        except Exception as e:
            print(f"âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
            return False

    def runAllExperiments(
        self,
        groups: list[ExperimentGroup],
        limit: int | None = None,
        topK: int = 5,
    ) -> list[dict[str, Any]]:
        """
        è¿è¡Œæ‰€æœ‰æŒ‡å®šçš„å®éªŒç»„

        Args:
            groups: è¦è¿è¡Œçš„å®éªŒç»„åˆ—è¡¨
            limit: é™åˆ¶æŸ¥è¯¢æ•°é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰
            topK: æ£€ç´¢è¿”å›æ•°é‡

        Returns:
            æ‰€æœ‰å®éªŒç»„çš„ç»“æœåˆ—è¡¨
        """
        queries = self._loadQueries()
        if limit:
            queries = queries[:limit]
            print(f"âš ï¸ é™åˆ¶æŸ¥è¯¢æ•°é‡ä¸º {limit} æ¡ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰")

        results = []

        for group in groups:
            if group == "norag":
                result = self.runNoRagExperiment(queries)
            else:
                result = self.runRagExperiment(queries, strategy=group, topK=topK)
            results.append(result)

        return results

    def saveResults(
        self,
        experimentResults: list[dict[str, Any]],
        reportPath: str,
        chartPath: str,
        markdownPath: str,
        detailedPath: str,
    ) -> None:
        """
        ä¿å­˜æ‰€æœ‰ç»“æœ

        Args:
            experimentResults: å®éªŒç»“æœåˆ—è¡¨
            reportPath: JSON æŠ¥å‘Šè·¯å¾„
            chartPath: å›¾è¡¨è·¯å¾„
            markdownPath: Markdown è¡¨æ ¼è·¯å¾„
            detailedPath: è¯¦ç»†ç»“æœè·¯å¾„
        """
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generateReport(experimentResults)

        # ä¿å­˜ JSON æŠ¥å‘Š
        with open(reportPath, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSON æŠ¥å‘Šå·²ä¿å­˜: {reportPath}")

        # ç”Ÿæˆå¹¶ä¿å­˜å›¾è¡¨
        self.generateChart(experimentResults, chartPath)

        # ç”Ÿæˆå¹¶ä¿å­˜ Markdown è¡¨æ ¼
        markdownTable = self.generateMarkdownTable(experimentResults)
        with open(markdownPath, "w", encoding="utf-8") as f:
            f.write(markdownTable)
        print(f"âœ… Markdown è¡¨æ ¼å·²ä¿å­˜: {markdownPath}")

        # ä¿å­˜è¯¦ç»†ç»“æœï¼ˆæ¯ç»„ä¸€ä¸ª JSONL æ–‡ä»¶ï¼‰
        for result in experimentResults:
            groupName = result["group"]
            groupDetailPath = detailedPath.replace(".jsonl", f"_{groupName}.jsonl")
            with open(groupDetailPath, "w", encoding="utf-8") as f:
                for r in result.get("results", []):
                    f.write(json.dumps(r, ensure_ascii=False) + "\n")
            print(f"âœ… è¯¦ç»†ç»“æœå·²ä¿å­˜: {groupDetailPath}")


def printSummary(experimentResults: list[dict[str, Any]]) -> None:
    """æ‰“å°å®éªŒç»“æœæ‘˜è¦"""
    print("\n" + "=" * 60)
    print("ğŸ“Š å®éªŒç»“æœæ±‡æ€»")
    print("=" * 60)

    print("\næ£€ç´¢æŒ‡æ ‡:")
    print(f"{'å®éªŒç»„':<20} {'Recall@5':<12} {'MRR':<12}")
    print("-" * 44)
    for result in experimentResults:
        group = result["group"]
        # norag æ²¡æœ‰æ£€ç´¢ï¼Œæ˜¾ç¤º N/A
        if result["strategy"] is None:
            print(f"{group:<20} {'N/A':<12} {'N/A':<12}")
        else:
            recall = result["retrieval_metrics"]["recall@5"]
            mrr = result["retrieval_metrics"]["mrr"]
            print(f"{group:<20} {recall:<12.4f} {mrr:<12.4f}")

    print("\nç”ŸæˆæŒ‡æ ‡:")
    print(f"{'å®éªŒç»„':<20} {'æœ¯è¯­å‘½ä¸­ç‡':<12} {'æ¥æºå¼•ç”¨ç‡':<12} {'å»¶è¿Ÿ(ms)':<12}")
    print("-" * 56)
    for result in experimentResults:
        group = result["group"]
        termHit = result["generation_metrics"]["term_hit_rate"]
        sourceCite = result["generation_metrics"]["source_citation_rate"]
        latency = result["avg_latency_ms"]
        print(f"{group:<20} {termHit:<12.4f} {sourceCite:<12.4f} {latency:<12.0f}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="RAG å¯¹æ¯”å®éªŒè„šæœ¬")
    parser.add_argument(
        "--groups",
        nargs="+",
        choices=["norag", "bm25", "vector", "hybrid"],
        default=["norag", "bm25", "vector", "hybrid"],
        help="è¦è¿è¡Œçš„å®éªŒç»„",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="é™åˆ¶æŸ¥è¯¢æ•°é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰",
    )
    parser.add_argument(
        "--topk",
        type=int,
        default=5,
        help="æ£€ç´¢è¿”å›æ•°é‡",
    )
    parser.add_argument(
        "--query-file",
        type=str,
        default=None,
        help="æµ‹è¯•æŸ¥è¯¢é›†æ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½•",
    )

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ“Š Math-RAG å¯¹æ¯”å®éªŒ")
    print("=" * 60)
    print(f"å®éªŒç»„: {', '.join(args.groups)}")
    print(f"Top-K: {args.topk}")
    if args.limit:
        print(f"æŸ¥è¯¢é™åˆ¶: {args.limit}")
    print("=" * 60)

    # åˆå§‹åŒ–å®éªŒè¿è¡Œå™¨
    runner = ExperimentRunner(
        queryFile=args.query_file,
        outputDir=args.output_dir,
    )

    # è¿è¡Œå®éªŒ
    results = runner.runAllExperiments(
        groups=args.groups,
        limit=args.limit,
        topK=args.topk,
    )

    # æ‰“å°æ‘˜è¦
    printSummary(results)

    # ä¿å­˜ç»“æœ
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    reportPath = os.path.join(runner.outputDir, "comparison_results.json")
    chartPath = os.path.join(runner.outputDir, "comparison_chart.png")
    markdownPath = os.path.join(runner.outputDir, "comparison_table.md")
    detailedPath = os.path.join(runner.outputDir, f"detailed_results_{timestamp}.jsonl")

    runner.saveResults(
        results,
        reportPath=reportPath,
        chartPath=chartPath,
        markdownPath=markdownPath,
        detailedPath=detailedPath,
    )

    # ä¿å­˜æ—¥å¿—
    logPath = os.path.join(runner.logDir, f"experiment_{timestamp}.json")
    with open(logPath, "w", encoding="utf-8") as f:
        logData = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "args": vars(args),
            "results_summary": [
                {
                    "group": r["group"],
                    "retrieval_metrics": r["retrieval_metrics"],
                    "generation_metrics": r["generation_metrics"],
                    "avg_latency_ms": r["avg_latency_ms"],
                }
                for r in results
            ],
        }
        json.dump(logData, f, ensure_ascii=False, indent=2)
    print(f"âœ… æ—¥å¿—å·²ä¿å­˜: {logPath}")

    print("\nâœ… å¯¹æ¯”å®éªŒå®Œæˆï¼")


if __name__ == "__main__":
    main()
