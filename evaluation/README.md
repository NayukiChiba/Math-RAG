# Evaluation æ¨¡å—

æ£€ç´¢è¯„æµ‹æ¨¡å—ï¼Œç”¨äºè¯„ä¼°ä¸åŒæ£€ç´¢æ–¹æ³•çš„æ€§èƒ½ã€‚

## æ¨¡å—è¯´æ˜

### evalRetrieval.py

æ£€ç´¢è¯„æµ‹è„šæœ¬ï¼Œè®¡ç®—å¤šç§è¯„æµ‹æŒ‡æ ‡å¹¶ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šã€‚

**åŠŸèƒ½**ï¼š
- åŠ è½½è¯„æµ‹æŸ¥è¯¢é›†
- è°ƒç”¨å¤šç§æ£€ç´¢æ–¹æ³•ï¼ˆBM25ã€Vectorã€Hybridï¼‰
- è®¡ç®—è¯„æµ‹æŒ‡æ ‡ï¼šRecall@Kã€MRRã€nDCG@Kã€MAP
- ç”Ÿæˆ JSON æŠ¥å‘Šå’Œå¯¹æ¯”å›¾è¡¨

**è¯„æµ‹æŒ‡æ ‡**ï¼š

1. **Recall@K**ï¼šåœ¨å‰ K ä¸ªç»“æœä¸­æ‰¾åˆ°çš„ç›¸å…³æ–‡æ¡£æ¯”ä¾‹
   - å…¬å¼ï¼š`Recall@K = å‰Kä¸ªç»“æœä¸­çš„ç›¸å…³æ–‡æ¡£æ•° / æ€»ç›¸å…³æ–‡æ¡£æ•°`
   - è¯´æ˜ï¼šè¡¡é‡æ£€ç´¢ç³»ç»Ÿçš„å¬å›èƒ½åŠ›

2. **MRR (Mean Reciprocal Rank)**ï¼šç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£æ’åå€’æ•°çš„å¹³å‡å€¼
   - å…¬å¼ï¼š`MRR = å¹³å‡(1 / ç¬¬ä¸€ä¸ªç›¸å…³æ–‡æ¡£çš„æ’å)`
   - è¯´æ˜ï¼šè¡¡é‡æœ€ç›¸å…³ç»“æœçš„æ’åä½ç½®

3. **nDCG@K (Normalized Discounted Cumulative Gain)**ï¼šè€ƒè™‘æ’åä½ç½®çš„ç›¸å…³æ€§è¯„åˆ†
   - å…¬å¼ï¼š`nDCG@K = DCG@K / IDCG@K`
   - è¯´æ˜ï¼šè€ƒè™‘ç›¸å…³æ€§ç¨‹åº¦å’Œæ’åä½ç½®ï¼Œå½’ä¸€åŒ–åˆ° 0-1

4. **MAP (Mean Average Precision)**ï¼šæ‰€æœ‰ç›¸å…³æ–‡æ¡£çš„ Precision å¹³å‡å€¼
   - å…¬å¼ï¼š`MAP = å¹³å‡(æ¯ä¸ªæŸ¥è¯¢çš„ AP)`
   - è¯´æ˜ï¼šç»¼åˆè€ƒè™‘ç²¾ç¡®åº¦å’Œå¬å›ç‡

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

è¯„æµ‹æ‰€æœ‰æ–¹æ³•ï¼ˆBM25ã€Vectorã€Hybrid-Weightedã€Hybrid-RRFï¼‰ï¼š

```bash
python evaluation/evalRetrieval.py
```

### æŒ‡å®šè¯„æµ‹æ–¹æ³•

ä»…è¯„æµ‹ BM25 å’Œ Vectorï¼š

```bash
python evaluation/evalRetrieval.py --methods bm25 vector
```

ä»…è¯„æµ‹æ··åˆæ–¹æ³•ï¼š

```bash
python evaluation/evalRetrieval.py --methods hybrid-weighted hybrid-rrf
```

### è°ƒæ•´ TopK é˜ˆå€¼

```bash
python evaluation/evalRetrieval.py --topk 20
```

### ç”Ÿæˆå¯¹æ¯”å›¾è¡¨

```bash
python evaluation/evalRetrieval.py --visualize
```

### æŒ‡å®šæŸ¥è¯¢é›†å’Œè¾“å‡ºè·¯å¾„

```bash
python evaluation/evalRetrieval.py \
    --queries data/evaluation/custom_queries.jsonl \
    --output outputs/reports/custom_metrics.json
```

### å®Œæ•´ç¤ºä¾‹

```bash
python evaluation/evalRetrieval.py \
    --methods bm25 vector hybrid-weighted hybrid-rrf \
    --topk 10 \
    --visualize \
    --output outputs/reports/retrieval_metrics.json
```

## è¾“å‡ºç»“æœ

### 1. JSON æŠ¥å‘Š

è¾“å‡ºæ–‡ä»¶ï¼š`outputs/reports/retrieval_metrics.json`

```json
{
  "timestamp": "2026-02-14 10:30:00",
  "queries_file": "data/evaluation/queries.jsonl",
  "total_queries": 35,
  "subject_distribution": {
    "æ•°å­¦åˆ†æ": 20,
    "é«˜ç­‰ä»£æ•°": 7,
    "æ¦‚ç‡è®º": 8
  },
  "topk": 10,
  "results": [
    {
      "method": "BM25",
      "total_queries": 35,
      "avg_metrics": {
        "recall@1": 0.8571,
        "recall@3": 0.9143,
        "recall@5": 0.9429,
        "recall@10": 0.9714,
        "mrr": 0.9048,
        "map": 0.8762,
        "ndcg@3": 0.9234,
        "ndcg@5": 0.9456,
        "ndcg@10": 0.9678
      },
      "avg_query_time": 0.0123
    }
  ]
}
```

### 2. å¯¹æ¯”å›¾è¡¨

è¾“å‡ºæ–‡ä»¶ï¼š`outputs/reports/retrieval_comparison.png`

åŒ…å«å››ä¸ªå­å›¾ï¼š
- Recall@K å¯¹æ¯”ï¼ˆK=1,3,5,10ï¼‰
- nDCG@K å¯¹æ¯”ï¼ˆK=3,5,10ï¼‰
- MRR å’Œ MAP å¯¹æ¯”
- å¹³å‡æŸ¥è¯¢æ—¶é—´å¯¹æ¯”

### 3. æ§åˆ¶å°è¾“å‡º

```
==============================================================
ğŸ“Š Math-RAG æ£€ç´¢è¯„æµ‹
==============================================================
æŸ¥è¯¢é›†: data/evaluation/queries.jsonl
è¯„æµ‹æ–¹æ³•: bm25, vector, hybrid-weighted, hybrid-rrf
TopK: 10
==============================================================

âœ… åŠ è½½äº† 35 æ¡æŸ¥è¯¢

ğŸ“š å­¦ç§‘åˆ†å¸ƒ:
  æ•°å­¦åˆ†æ: 20 æ¡
  æ¦‚ç‡è®º: 8 æ¡
  é«˜ç­‰ä»£æ•°: 7 æ¡

==============================================================
ğŸ“Š è¯„æµ‹æ–¹æ³•: BM25
==============================================================

ğŸ“ˆ å¹³å‡æŒ‡æ ‡:
  Recall@1:  0.8571
  Recall@3:  0.9143
  Recall@5:  0.9429
  Recall@10: 0.9714
  MRR:       0.9048
  MAP:       0.8762
  nDCG@3:    0.9234
  nDCG@5:    0.9456
  nDCG@10:   0.9678
  å¹³å‡æŸ¥è¯¢æ—¶é—´: 12.34ms

==============================================================
ğŸ“Š è¯„æµ‹ç»“æœæ±‡æ€»
==============================================================
æ–¹æ³•                  Recall@1   Recall@10  MRR        MAP        nDCG@10    æŸ¥è¯¢æ—¶é—´  
------------------------------------------------------------------------------------------
BM25                 0.8571     0.9714     0.9048     0.8762     0.9678     12.34ms   
Vector               0.8286     0.9571     0.8857     0.8524     0.9542     23.45ms   
Hybrid-Weighted      0.8857     0.9857     0.9238     0.8976     0.9789     35.67ms   
Hybrid-RRF           0.9000     0.9857     0.9333     0.9087     0.9823     36.12ms   

âœ… è¯„æµ‹å®Œæˆï¼
```

## è¯„æµ‹æ•°æ®é›†

è¯„æµ‹æ•°æ®é›†ä½äº `data/evaluation/queries.jsonl`ï¼Œæ ¼å¼ä¸ºï¼š

```json
{"query": "ä¸€è‡´æ”¶æ•›", "relevant_terms": ["ä¸€è‡´æ”¶æ•›"], "subject": "æ•°å­¦åˆ†æ"}
{"query": "é€ç‚¹æ”¶æ•›", "relevant_terms": ["é€ç‚¹æ”¶æ•›", "ä¸€è‡´æ”¶æ•›"], "subject": "æ•°å­¦åˆ†æ"}
```

è¯¦è§ `data/evaluation/README.md` äº†è§£æ•°æ®é›†æ ¼å¼å’Œæ‰©å±•æŒ‡å—ã€‚

## æ³¨æ„äº‹é¡¹

1. **é¦–æ¬¡è¿è¡Œ**ï¼šç¡®ä¿å·²æ„å»ºè¯­æ–™åº“å’Œç´¢å¼•
   ```bash
   python retrieval/buildCorpus.py
   python retrieval/retrievalBM25.py --build
   python retrieval/retrievalVector.py --build
   ```

2. **ä¾èµ–åº“**ï¼šéœ€è¦å®‰è£…ä»¥ä¸‹ä¾èµ–
   - `rank-bm25`ï¼šBM25 æ£€ç´¢
   - `sentence-transformers`ï¼šå‘é‡æ£€ç´¢
   - `faiss-gpu` æˆ– `faiss-cpu`ï¼šå‘é‡ç´¢å¼•
   - `matplotlib`ï¼šå›¾è¡¨ç”Ÿæˆï¼ˆå¯é€‰ï¼‰
   - `numpy`ï¼šæ•°å€¼è®¡ç®—

3. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨ GPU åŠ é€Ÿå‘é‡æ£€ç´¢ï¼ˆéœ€è¦ `faiss-gpu`ï¼‰
   - è°ƒæ•´ TopK é˜ˆå€¼ä»¥å¹³è¡¡æ€§èƒ½å’ŒæŒ‡æ ‡
   - æ‰¹é‡è¯„æµ‹æ—¶å»ºè®®ç¦ç”¨è¯¦ç»†æ—¥å¿—

4. **è¯„æµ‹æ•°æ®è´¨é‡**ï¼š
   - ç¡®ä¿ `relevant_terms` ä¸­çš„æœ¯è¯­åœ¨ corpus ä¸­å­˜åœ¨
   - æœ¯è¯­åˆ—è¡¨åº”æŒ‰ç›¸å…³æ€§ä»é«˜åˆ°ä½æ’åº
   - å»ºè®®è¯„æµ‹é›†åŒ…å« 50-100 æ¡æŸ¥è¯¢ä»¥è·å¾—å¯é æŒ‡æ ‡

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„è¯„æµ‹æŒ‡æ ‡

åœ¨ `evalRetrieval.py` ä¸­æ·»åŠ æ–°çš„æŒ‡æ ‡è®¡ç®—å‡½æ•°ï¼š

```python
def calculateNewMetric(results: list[dict], relevantTerms: list[str]) -> float:
    """è®¡ç®—æ–°æŒ‡æ ‡"""
    # å®ç°é€»è¾‘
    return score
```

ç„¶ååœ¨ `evaluateMethod()` å‡½æ•°ä¸­è°ƒç”¨ï¼š

```python
metrics["new_metric"].append(calculateNewMetric(results, relevantTerms))
```

### æ·»åŠ æ–°çš„æ£€ç´¢æ–¹æ³•

åœ¨ `main()` å‡½æ•°ä¸­åˆå§‹åŒ–æ–°çš„æ£€ç´¢å™¨ï¼š

```python
if method == "new_method":
    retrievers["NewMethod"] = NewRetriever(corpusPath)
```

å¹¶åœ¨ `argparse` ä¸­æ·»åŠ é€‰é¡¹ï¼š

```python
parser.add_argument(
    "--methods",
    choices=["bm25", "vector", "hybrid-weighted", "hybrid-rrf", "new_method"],
    ...
)
```

## ç›¸å…³æ–‡æ¡£

- [æ•°æ®é›†è¯´æ˜](../data/evaluation/README.md)
- [BM25 æ£€ç´¢](../retrieval/README.md#retrievalbm25py)
- [å‘é‡æ£€ç´¢](../retrieval/README.md#retrievalvectorpy)
- [æ··åˆæ£€ç´¢](../retrieval/README.md#retrievalhybridpy)
