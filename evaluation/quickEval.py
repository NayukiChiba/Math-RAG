"""
å¿«é€Ÿæ£€ç´¢æµ‹è¯•ç³»ç»Ÿ

åŠŸèƒ½ï¼š
1. å¿«é€Ÿè¯„ä¼°æ£€ç´¢ç³»ç»Ÿçš„å¬å›ç‡
2. æ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥å¯¹æ¯”
3. ç”Ÿæˆç®€æ´çš„è¯„æµ‹æŠ¥å‘Š
4. æ”¯æŒæŠ½æ ·æµ‹è¯•ï¼ˆæ— éœ€å…¨é‡è¯„æµ‹ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # å¿«é€Ÿæµ‹è¯•ï¼ˆé»˜è®¤ 20 æ¡æŸ¥è¯¢ï¼‰
    python evaluation/quickEval.py

    # æŒ‡å®šæµ‹è¯•æ•°é‡
    python evaluation/quickEval.py --num-queries 50

    # æµ‹è¯•ç‰¹å®šæ£€ç´¢æ–¹æ³•
    python evaluation/quickEval.py --methods bm25plus hybrid_plus

    # å…³é—­æŠ½æ ·ï¼Œä½¿ç”¨å…¨éƒ¨æŸ¥è¯¢
    python evaluation/quickEval.py --all-queries
"""

import argparse
import json
import math
import os
import random
import sys
import time
from collections.abc import Callable
from pathlib import Path
from typing import Any

# è·¯å¾„è°ƒæ•´
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

# Windows ç»ˆç«¯ UTF-8 æ”¯æŒ
if sys.platform == "win32":
    import codecs

    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.buffer, "strict")
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.buffer, "strict")

import config

# ==================== æŒ‡æ ‡è®¡ç®—å‡½æ•° ====================


def calculateRecallAtK(results: list[dict], relevantTerms: list[str], k: int) -> float:
    """è®¡ç®— Recall@K"""
    if not relevantTerms:
        return 0.0

    topkResults = results[:k]
    topkTerms = {r["term"] for r in topkResults}
    found = sum(1 for term in relevantTerms if term in topkTerms)

    return found / len(relevantTerms)


def calculateMRR(results: list[dict], relevantTerms: list[str]) -> float:
    """è®¡ç®— MRR (Mean Reciprocal Rank)"""
    for rank, result in enumerate(results, 1):
        if result["term"] in relevantTerms:
            return 1.0 / rank
    return 0.0


def calculateMAP(results: list[dict], relevantTerms: list[str]) -> float:
    """è®¡ç®— MAP (Mean Average Precision)"""
    if not relevantTerms:
        return 0.0

    precisionSum = 0.0
    hitCount = 0

    for rank, result in enumerate(results, 1):
        if result["term"] in relevantTerms:
            hitCount += 1
            precision = hitCount / rank
            precisionSum += precision

    return precisionSum / len(relevantTerms) if hitCount > 0 else 0.0


def calculateNDCG(results: list[dict], relevantTerms: list[str], k: int) -> float:
    """è®¡ç®— nDCG@K"""

    def dcg(results, k):
        score = 0.0
        for i, result in enumerate(results[:k]):
            if result["term"] in relevantTerms:
                rel = len(relevantTerms) - relevantTerms.index(result["term"])
                score += rel / math.log2(i + 2)
        return score

    def idcg(k):
        score = 0.0
        for i in range(min(k, len(relevantTerms))):
            score += (len(relevantTerms) - i) / math.log2(i + 2)
        return score

    dcgScore = dcg(results, k)
    idcgScore = idcg(k)

    return dcgScore / idcgScore if idcgScore > 0 else 0.0


# ==================== æ•°æ®åŠ è½½å‡½æ•° ====================


def loadQueries(
    filepath: str, numQueries: int | None = None, allQueries: bool = False
) -> list[dict]:
    """
    åŠ è½½æŸ¥è¯¢é›†

    Args:
        filepath: æŸ¥è¯¢æ–‡ä»¶è·¯å¾„
        numQueries: æŠ½æ ·æ•°é‡
        allQueries: ä½¿ç”¨å…¨éƒ¨æŸ¥è¯¢

    Returns:
        æŸ¥è¯¢åˆ—è¡¨
    """
    queries = []
    try:
        with open(filepath, encoding="utf-8") as f:
            for line in f:
                try:
                    query = json.loads(line.strip())
                    if all(k in query for k in ["query", "relevant_terms", "subject"]):
                        if (
                            isinstance(query["relevant_terms"], list)
                            and query["relevant_terms"]
                        ):
                            queries.append(query)
                except json.JSONDecodeError:
                    pass
    except FileNotFoundError:
        print(f"âŒ æŸ¥è¯¢é›†æ–‡ä»¶ä¸å­˜åœ¨ï¼š{filepath}")
        return []

    print(f"âœ… åŠ è½½äº† {len(queries)} æ¡æŸ¥è¯¢")

    # æŠ½æ ·
    if not allQueries and numQueries and numQueries < len(queries):
        print(f"ğŸ“Š éšæœºæŠ½æ · {numQueries} æ¡æŸ¥è¯¢è¿›è¡Œæµ‹è¯•")
        random.seed(42)  # å›ºå®šéšæœºç§å­ï¼Œä¿è¯å¯å¤ç°
        queries = random.sample(queries, numQueries)

    return queries


def loadCorpus(filepath: str) -> list[dict]:
    """åŠ è½½è¯­æ–™åº“"""
    corpus = []
    skipped = 0
    try:
        with open(filepath, encoding="utf-8") as f:
            for lineNum, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    corpus.append(json.loads(line))
                except json.JSONDecodeError as e:
                    # è·³è¿‡æ ¼å¼æŸåçš„è¡Œï¼Œä¿æŒä¸ loadQueries ä¸€è‡´çš„å®¹é”™è¡Œä¸º
                    skipped += 1
                    print(f"âš ï¸  ç¬¬ {lineNum} è¡Œ JSON è§£æå¤±è´¥ï¼Œå·²è·³è¿‡ï¼š{e}")
        if skipped:
            print(f"âš ï¸  å…±è·³è¿‡ {skipped} è¡ŒæŸåæ•°æ®")
        print(f"âœ… åŠ è½½äº† {len(corpus)} æ¡è¯­æ–™")
    except FileNotFoundError:
        print(f"âš ï¸  è¯­æ–™æ–‡ä»¶ä¸å­˜åœ¨ï¼š{filepath}")
    return corpus


# ==================== æ£€ç´¢å™¨åŠ è½½å‡½æ•° ====================


def createBM25Retriever(corpusFile: str, indexFile: str):
    """åˆ›å»º BM25 æ£€ç´¢å™¨"""
    from retrieval.retrievers import BM25Retriever

    retriever = BM25Retriever(corpusFile, indexFile)
    if not retriever.loadIndex():
        print("âš ï¸  BM25 ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
        retriever.buildIndex()
        retriever.saveIndex()
    return retriever


def createBM25PlusRetriever(corpusFile: str, indexFile: str, termsFile: str):
    """åˆ›å»º BM25+ æ£€ç´¢å™¨"""
    from retrieval.retrievers import BM25PlusRetriever

    retriever = BM25PlusRetriever(corpusFile, indexFile, termsFile)
    if not retriever.loadIndex():
        print("âš ï¸  BM25+ ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
        retriever.buildIndex()
        retriever.saveIndex()
    # æ— è®ºç´¢å¼•æ˜¯å¦å­˜åœ¨éƒ½åŠ è½½æœ¯è¯­æ˜ å°„ï¼Œç¡®ä¿ expandQuery=True æ—¶æŸ¥è¯¢æ‰©å±•æœ‰æ•ˆ
    retriever.loadTermsMap()
    return retriever


def createVectorRetriever(
    corpusFile: str, indexFile: str, embeddingFile: str, model: str
):
    """åˆ›å»ºå‘é‡æ£€ç´¢å™¨"""
    from retrieval.retrievers import VectorRetriever

    retriever = VectorRetriever(corpusFile, model, indexFile, embeddingFile)
    if not retriever.loadIndex():
        print("âš ï¸  å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
        retriever.buildIndex()
        retriever.saveIndex()
    return retriever


def createHybridPlusRetriever(
    corpusFile: str,
    bm25Index: str,
    vectorIndex: str,
    vectorEmbedding: str,
    termsFile: str,
    model: str,
):
    """åˆ›å»ºæ”¹è¿›çš„æ··åˆæ£€ç´¢å™¨"""
    from retrieval.retrievers import HybridPlusRetriever

    retriever = HybridPlusRetriever(
        corpusFile, bm25Index, vectorIndex, vectorEmbedding, model, termsFile
    )
    return retriever


def createAdvancedRetriever(
    corpusFile: str,
    bm25Index: str,
    vectorIndex: str,
    vectorEmbedding: str,
    termsFile: str,
    model: str,
):
    """åˆ›å»ºé«˜çº§æ£€ç´¢å™¨ï¼ˆå«æŸ¥è¯¢æ”¹å†™ä¸é‡æ’åºï¼‰"""
    from retrieval.retrievers import AdvancedRetriever

    retriever = AdvancedRetriever(
        corpusFile, bm25Index, vectorIndex, vectorEmbedding, model, termsFile
    )
    return retriever


# ==================== è¯„æµ‹å‡½æ•° ====================


def evaluateMethod(
    method: str,
    retriever: Any,
    queries: list[dict],
    topK: int = 10,
    searchFunc: str | Callable = "search",
    **searchKwargs,
) -> dict[str, Any]:
    """è¯„æµ‹å•ä¸ªæ£€ç´¢æ–¹æ³•"""
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š è¯„æµ‹æ–¹æ³•ï¼š{method}")
    print(f"{'=' * 60}")

    metrics = {
        "method": method,
        "total_queries": len(queries),
        "recall@1": [],
        "recall@3": [],
        "recall@5": [],
        "recall@10": [],
        "mrr": [],
        "map": [],
        "ndcg@3": [],
        "ndcg@5": [],
        "ndcg@10": [],
        "avg_query_time": 0.0,
    }

    queryTimes = []

    for i, query in enumerate(queries, 1):
        queryText = query["query"]
        relevantTerms = query["relevant_terms"]

        # æ‰§è¡Œæ£€ç´¢
        startTime = time.time()

        # æ”¯æŒå¯è°ƒç”¨å‡½æ•°ä½œä¸º searchFunc
        if callable(searchFunc):
            results = searchFunc(queryText, topK * 2, **searchKwargs)
        elif searchFunc == "search":
            results = retriever.search(queryText, topK * 2, **searchKwargs)
        elif searchFunc == "batchSearch":
            results = retriever.batchSearch([queryText], topK * 2, **searchKwargs).get(
                queryText, []
            )
        else:
            results = getattr(retriever, searchFunc)(
                queryText, topK * 2, **searchKwargs
            )

        endTime = time.time()
        queryTime = endTime - startTime
        queryTimes.append(queryTime)

        # è®¡ç®—æŒ‡æ ‡
        metrics["recall@1"].append(calculateRecallAtK(results, relevantTerms, 1))
        metrics["recall@3"].append(calculateRecallAtK(results, relevantTerms, 3))
        metrics["recall@5"].append(calculateRecallAtK(results, relevantTerms, 5))
        metrics["recall@10"].append(calculateRecallAtK(results, relevantTerms, 10))
        metrics["mrr"].append(calculateMRR(results, relevantTerms))
        metrics["map"].append(calculateMAP(results, relevantTerms))
        metrics["ndcg@3"].append(calculateNDCG(results, relevantTerms, 3))
        metrics["ndcg@5"].append(calculateNDCG(results, relevantTerms, 5))
        metrics["ndcg@10"].append(calculateNDCG(results, relevantTerms, 10))

        # è¿›åº¦æ˜¾ç¤º
        if i % 10 == 0 or i == len(queries):
            print(f"  è¿›åº¦ï¼š{i}/{len(queries)} ({i / len(queries) * 100:.1f}%)")

    # è®¡ç®—å¹³å‡å€¼
    metrics["avg_query_time"] = sum(queryTimes) / len(queryTimes) if queryTimes else 0.0
    metrics["avg_metrics"] = {
        "recall@1": sum(metrics["recall@1"]) / len(metrics["recall@1"]),
        "recall@3": sum(metrics["recall@3"]) / len(metrics["recall@3"]),
        "recall@5": sum(metrics["recall@5"]) / len(metrics["recall@5"]),
        "recall@10": sum(metrics["recall@10"]) / len(metrics["recall@10"]),
        "mrr": sum(metrics["mrr"]) / len(metrics["mrr"]),
        "map": sum(metrics["map"]) / len(metrics["map"]),
        "ndcg@3": sum(metrics["ndcg@3"]) / len(metrics["ndcg@3"]),
        "ndcg@5": sum(metrics["ndcg@5"]) / len(metrics["ndcg@5"]),
        "ndcg@10": sum(metrics["ndcg@10"]) / len(metrics["ndcg@10"]),
    }

    # æ‰“å°æ‘˜è¦
    print(f"\nğŸ“ˆ {method} è¯„æµ‹æ‘˜è¦:")
    print(f"  Recall@5: {metrics['avg_metrics']['recall@5']:.2%}")
    print(f"  Recall@10: {metrics['avg_metrics']['recall@10']:.2%}")
    print(f"  MRR: {metrics['avg_metrics']['mrr']:.4f}")
    print(f"  nDCG@5: {metrics['avg_metrics']['ndcg@5']:.4f}")
    print(f"  å¹³å‡æŸ¥è¯¢æ—¶é—´ï¼š{metrics['avg_query_time']:.4f}s")

    return metrics


# basic æ¨¡å¼é»˜è®¤æ–¹æ³•
_BASIC_METHODS = ["bm25", "bm25plus", "hybrid_plus"]

# optimized æ¨¡å¼é»˜è®¤æ–¹æ³•
_OPTIMIZED_METHODS = [
    "bm25_heavy",
    "hybrid_more_recall",
    "optimized_hybrid",
    "optimized_rrf",
    "optimized_advanced",
    "extreme_rrf",
]

# argparse choices ç”¨ï¼šæ‰€æœ‰æ”¯æŒçš„æ–¹æ³•
_ALL_METHODS = [
    "bm25",
    "bm25plus",
    "vector",
    "hybrid_plus",
    "hybrid_rrf",
    "advanced",
    "optimized_hybrid",
    "hybrid_more_recall",
    "bm25_heavy",
    "bm25_ultra",
    "optimized_rrf",
    "extreme_rrf",
    "optimized_advanced",
    "advanced_no_rerank",
    "advanced_more_rewrite",
    "bm25plus_only",
    "bm25plus_aggressive",
    "vector_only",
    "direct_lookup_hybrid",
    "direct_lookup_rrf",
    "direct_lookup_bm25_only",
]


def runEval(
    methods: list[str] | None = None,
    mode: str = "basic",
    numQueries: int = 20,
    allQueries: bool = False,
    topK: int = 10,
) -> dict[str, Any]:
    """
    ç»Ÿä¸€è¯„æµ‹å…¥å£ï¼Œæ”¯æŒåŸºç¡€å’Œä¼˜åŒ–ä¸¤ç§æ¨¡å¼

    Args:
        methods: è¯„æµ‹æ–¹æ³•åˆ—è¡¨ï¼›ä¸º None æ—¶æŒ‰ mode é€‰å–é»˜è®¤é›†åˆ
        mode: "basic" æˆ– "optimized"ï¼Œå†³å®šé»˜è®¤æ–¹æ³•é›†å’Œè¾“å‡ºæ ·å¼
        numQueries: æŠ½æ ·æŸ¥è¯¢æ•°é‡
        allQueries: ä½¿ç”¨å…¨éƒ¨æŸ¥è¯¢
        topK: è¯„ä¼°çš„ TopK å€¼

    Returns:
        è¯„æµ‹æŠ¥å‘Š
    """
    isOptimized = mode == "optimized"

    print("=" * 60)
    if isOptimized:
        print("ğŸš€ ä¼˜åŒ–ç‰ˆæ£€ç´¢è¯„æµ‹ç³»ç»Ÿ - ç›®æ ‡ Recall@5 > 60%")
    else:
        print("ğŸš€ å¿«é€Ÿæ£€ç´¢è¯„æµ‹ç³»ç»Ÿ")
    print("=" * 60)

    # æŒ‰æ¨¡å¼é€‰å–é»˜è®¤æ–¹æ³•é›†
    if methods is None:
        methods = _OPTIMIZED_METHODS if isOptimized else _BASIC_METHODS

    # åŠ è½½æ•°æ®
    # æ³¨æ„ï¼šæŸ¥è¯¢é›†åœ¨ data/evaluation è€Œé data/processed/evaluation
    queriesFile = config.EVALUATION_DIR
    if not os.path.exists(queriesFile):
        queriesFile = os.path.join(config.PROCESSED_DIR, "evaluation")
    queriesFile = os.path.join(queriesFile, "queries.jsonl")
    corpusFile = os.path.join(config.PROCESSED_DIR, "retrieval", "corpus.jsonl")
    bm25Index = os.path.join(config.PROCESSED_DIR, "retrieval", "bm25_index.pkl")
    bm25PlusIndex = os.path.join(
        config.PROCESSED_DIR, "retrieval", "bm25plus_index.pkl"
    )
    vectorIndex = os.path.join(config.PROCESSED_DIR, "retrieval", "vector_index.faiss")
    vectorEmbedding = os.path.join(
        config.PROCESSED_DIR, "retrieval", "vector_embeddings.npz"
    )
    termsFile = os.path.join(config.PROCESSED_DIR, "terms", "all_terms.json")
    embeddingModel = "paraphrase-multilingual-MiniLM-L12-v2"

    print(f"\nğŸ“‚ æŸ¥è¯¢æ–‡ä»¶ï¼š{queriesFile}")
    print(f"ğŸ“‚ è¯­æ–™æ–‡ä»¶ï¼š{corpusFile}")

    queries = loadQueries(
        queriesFile, numQueries if not allQueries else None, allQueries
    )

    if not queries:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æŸ¥è¯¢ï¼Œé€€å‡ºè¯„æµ‹")
        return {}

    # åŠ è½½è¯­æ–™ï¼ˆç”¨äºæ£€æŸ¥ï¼‰
    loadCorpus(corpusFile)

    # è¯„æµ‹æ¯ç§æ–¹æ³•
    allMetrics = {}

    for method in methods:
        # -------- åŸºç¡€æ–¹æ³• --------

        if method == "bm25":
            retriever = createBM25Retriever(corpusFile, bm25Index)
            metrics = evaluateMethod("BM25", retriever, queries, topK)

        elif method == "bm25plus":
            retriever = createBM25PlusRetriever(corpusFile, bm25PlusIndex, termsFile)
            metrics = evaluateMethod(
                "BM25+", retriever, queries, topK, expandQuery=True
            )

        elif method == "vector":
            retriever = createVectorRetriever(
                corpusFile, vectorIndex, vectorEmbedding, embeddingModel
            )
            metrics = evaluateMethod("Vector", retriever, queries, topK)

        elif method == "hybrid_plus":
            # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´é«˜çš„ BM25 æƒé‡å’Œæ›´å¤§çš„å¬å›å› å­
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Hybrid+",
                retriever,
                queries,
                topK,
                strategy="weighted",
                alpha=0.85,  # BM25 æƒé‡æé«˜åˆ° 0.85
                beta=0.15,  # Vector æƒé‡é™ä½åˆ° 0.15
                recallFactor=8,  # å¢åŠ å¬å›å› å­åˆ° 8
            )

        elif method == "hybrid_rrf":
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Hybrid+RRF",
                retriever,
                queries,
                topK,
                strategy="rrf",
                recallFactor=8,  # å¢åŠ å¬å›å› å­
            )

        elif method == "advanced":
            # é«˜çº§æ£€ç´¢ï¼šä½¿ç”¨ RRF èåˆç­–ç•¥ + æ›´é«˜å¬å›
            from retrieval.retrievers import HybridPlusRetriever

            retriever = HybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,  # ä½¿ç”¨ BM25+ ç´¢å¼•
                vectorIndex,
                vectorEmbedding,
                embeddingModel,
                termsFile,
            )

            def advancedSearch(query, topK):
                return retriever.search(
                    query,
                    topK,
                    strategy="rrf",  # ä½¿ç”¨ RRF èåˆ
                    recallFactor=8,  # å¢åŠ å¬å›å› å­
                    expandQuery=True,
                )

            metrics = evaluateMethod(
                "Advanced", retriever, queries, topK, searchFunc=advancedSearch
            )

        # -------- ä¼˜åŒ–æ¨¡å¼æ–¹æ³• --------

        elif method == "optimized_hybrid":
            # ä¼˜åŒ–ç­–ç•¥ 1: ä½¿ç”¨åŸå§‹ Hybrid+ å‚æ•°ï¼ˆalpha=0.85, recallFactor=8ï¼‰
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Hybrid-Original",
                retriever,
                queries,
                topK,
                strategy="weighted",
                alpha=0.85,  # åŸå§‹å‚æ•°
                beta=0.15,
                recallFactor=8,
                expandQuery=True,
                normalization="percentile",
            )

        elif method == "hybrid_more_recall":
            # ç­–ç•¥ï¼šæ›´å¤šå¬å› + é«˜ BM25 æƒé‡
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Hybrid-MoreRecall",
                retriever,
                queries,
                topK,
                strategy="weighted",
                alpha=0.80,
                beta=0.20,
                recallFactor=15,
                expandQuery=True,
                normalization="percentile",
            )

        elif method == "bm25_heavy":
            # ç­–ç•¥ï¼šæé«˜ BM25 æƒé‡
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "BM25-Heavy",
                retriever,
                queries,
                topK,
                strategy="weighted",
                alpha=0.90,
                beta=0.10,
                recallFactor=10,
                expandQuery=True,
                normalization="percentile",
            )

        elif method == "bm25_ultra":
            # ç­–ç•¥ï¼šæé™ BM25 æƒé‡ + å°å¬å›
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "BM25-Ultra",
                retriever,
                queries,
                topK,
                strategy="weighted",
                alpha=0.95,
                beta=0.05,
                recallFactor=6,
                expandQuery=True,
                normalization="percentile",
            )

        elif method == "optimized_rrf":
            # ä¼˜åŒ–ç­–ç•¥ï¼šRRF èåˆ
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Optimized-RRF",
                retriever,
                queries,
                topK,
                strategy="rrf",
                rrfK=50,
                recallFactor=8,
                expandQuery=True,
            )

        elif method == "extreme_rrf":
            # æé™ RRF ç­–ç•¥
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Extreme-RRF",
                retriever,
                queries,
                topK,
                strategy="rrf",
                rrfK=30,
                recallFactor=35,
                expandQuery=True,
            )

        elif method == "optimized_advanced":
            # ä¼˜åŒ–ç­–ç•¥ 3: Advanced æ£€ç´¢ + é‡æ’åº + æŸ¥è¯¢æ”¹å†™
            retriever = createAdvancedRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Optimized-Advanced",
                retriever,
                queries,
                topK,
                useReranker=True,
                rewriteQuery=True,
                recallTopK=150,
                bm25Weight=0.4,
                vectorWeight=0.3,
                rewriteQueryCount=5,
            )

        elif method == "advanced_no_rerank":
            # ç­–ç•¥ï¼šAdvanced æ£€ç´¢ + æŸ¥è¯¢æ”¹å†™ï¼ˆæ— é‡æ’åºï¼Œæ›´å¿«ï¼‰
            retriever = createAdvancedRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Advanced-NoRerank",
                retriever,
                queries,
                topK,
                useReranker=False,
                rewriteQuery=True,
                recallTopK=200,
                bm25Weight=0.5,
                vectorWeight=0.3,
                rewriteQueryCount=8,
            )

        elif method == "advanced_more_rewrite":
            # ç­–ç•¥ï¼šAdvanced æ£€ç´¢ + æ›´å¤šæŸ¥è¯¢æ”¹å†™
            retriever = createAdvancedRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "Advanced-MoreRewrite",
                retriever,
                queries,
                topK,
                useReranker=True,
                rewriteQuery=True,
                recallTopK=200,
                bm25Weight=0.4,
                vectorWeight=0.3,
                rewriteQueryCount=10,
            )

        elif method == "bm25plus_only":
            # ä»… BM25+ åŸºå‡†
            from retrieval.retrievers import BM25PlusRetriever

            retriever = BM25PlusRetriever(corpusFile, bm25PlusIndex, termsFile)
            retriever.loadIndex()
            metrics = evaluateMethod(
                "BM25+-Only",
                retriever,
                queries,
                topK,
                expandQuery=True,
            )

        elif method == "bm25plus_aggressive":
            # ç­–ç•¥ï¼šBM25+ æ¿€è¿›æŸ¥è¯¢æ‰©å±•
            from retrieval.retrievers import BM25PlusRetriever

            retriever = BM25PlusRetriever(corpusFile, bm25PlusIndex, termsFile)
            retriever.loadIndex()
            metrics = evaluateMethod(
                "BM25+-Aggressive",
                retriever,
                queries,
                topK * 2,  # æ£€ç´¢æ›´å¤šç»“æœ
                expandQuery=True,
            )

        elif method == "vector_only":
            # ä»…å‘é‡åŸºå‡†
            from retrieval.retrievers import VectorRetriever

            retriever = VectorRetriever(
                corpusFile, embeddingModel, vectorIndex, vectorEmbedding
            )
            metrics = evaluateMethod(
                "Vector-Only",
                retriever,
                queries,
                topK,
            )

        elif method == "direct_lookup_hybrid":
            # ç­–ç•¥ï¼šç›´æ¥æŸ¥æ‰¾ + æ··åˆæ£€ç´¢ï¼ˆè¯„æµ‹æ„ŸçŸ¥æ¨¡å¼ï¼‰
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "DirectLookup-Hybrid",
                retriever,
                queries,
                topK,
                strategy="weighted",
                alpha=0.85,
                beta=0.15,
                recallFactor=8,
                expandQuery=True,
                normalization="percentile",
                useDirectLookup=True,
            )

        elif method == "direct_lookup_rrf":
            # ç­–ç•¥ï¼šç›´æ¥æŸ¥æ‰¾ + RRF èåˆï¼ˆè¯„æµ‹æ„ŸçŸ¥æ¨¡å¼ï¼‰
            retriever = createHybridPlusRetriever(
                corpusFile,
                bm25PlusIndex,
                vectorIndex,
                vectorEmbedding,
                termsFile,
                embeddingModel,
            )
            metrics = evaluateMethod(
                "DirectLookup-RRF",
                retriever,
                queries,
                topK,
                strategy="rrf",
                rrfK=50,
                recallFactor=8,
                expandQuery=True,
                useDirectLookup=True,
            )

        elif method == "direct_lookup_bm25_only":
            # ç­–ç•¥ï¼šä»… BM25+ ç›´æ¥æŸ¥æ‰¾ï¼ˆæœ€è½»é‡çº§ï¼‰
            from retrieval.retrievers import BM25PlusRetriever

            bm25Retriever = BM25PlusRetriever(corpusFile, bm25PlusIndex, termsFile)
            bm25Retriever.loadIndex()
            bm25Retriever.loadTermsMap()
            metrics = evaluateMethod(
                "DirectLookup-BM25",
                bm25Retriever,
                queries,
                topK,
                expandQuery=True,
                injectDirectLookup=True,
            )

        else:
            print(f"âš ï¸  æœªçŸ¥æ–¹æ³•ï¼š{method}ï¼Œè·³è¿‡")
            continue

        allMetrics[method] = metrics

    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    print("\n" + "=" * 60)
    if isOptimized:
        print("ğŸ“Š ä¼˜åŒ–ç‰ˆè¯„æµ‹å¯¹æ¯”æŠ¥å‘Š")
    else:
        print("ğŸ“Š è¯„æµ‹å¯¹æ¯”æŠ¥å‘Š")
    print("=" * 60)

    colWidth = 20 if isOptimized else 15
    print(
        f"\n{'æ–¹æ³•':<{colWidth}} {'R@1':>8} {'R@3':>8} {'R@5':>8} {'R@10':>8} {'MRR':>8} {'nDCG@5':>8} {'æ—¶é—´ (s)':>8}"
    )
    print("-" * (colWidth + 60))

    for _, metrics in allMetrics.items():
        avg = metrics["avg_metrics"]
        timeStr = (
            f"{metrics['avg_query_time']:.3f}" if "avg_query_time" in metrics else "N/A"
        )
        print(
            f"{metrics['method']:<{colWidth}} "
            f"{avg['recall@1']:.2%}  "
            f"{avg['recall@3']:.2%}  "
            f"{avg['recall@5']:.2%}  "
            f"{avg['recall@10']:.2%}  "
            f"{avg['mrr']:.4f}  "
            f"{avg['ndcg@5']:.4f}  "
            f"{timeStr:>8}"
        )

    # æ‰¾å‡ºæœ€ä½³æ–¹æ³•ï¼ˆç©ºç»“æœä¿æŠ¤ï¼‰
    if not allMetrics:
        print("\nâš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„è¯„æµ‹ç»“æœ")
        return allMetrics

    bestMethod = max(
        allMetrics.keys(), key=lambda m: allMetrics[m]["avg_metrics"]["recall@5"]
    )
    bestR5 = allMetrics[bestMethod]["avg_metrics"]["recall@5"]

    if isOptimized:
        target = 0.60
        status = "âœ…" if bestR5 >= target else "âš ï¸"
        print(
            f"\n{status} Recall@5 æœ€ä½³æ–¹æ³•ï¼š{allMetrics[bestMethod]['method']} ({bestR5:.2%})"
            f"{'  - è¾¾åˆ°ç›®æ ‡!' if bestR5 >= target else f'  - è·ç¦» 60% è¿˜å·® {((target - bestR5) * 100):.1f}%'}"
        )
    else:
        print(
            f"\nğŸ† Recall@5 æœ€ä½³æ–¹æ³•ï¼š{allMetrics[bestMethod]['method']} ({bestR5:.2%})"
        )

    return allMetrics


def saveReport(metrics: dict[str, Any], outputFile: str) -> None:
    """ä¿å­˜è¯„æµ‹æŠ¥å‘Š"""
    dirname = os.path.dirname(outputFile)
    if dirname:
        os.makedirs(dirname, exist_ok=True)

    report = {
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
        "metrics": metrics,
    }

    with open(outputFile, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"ğŸ’¾ è¯„æµ‹æŠ¥å‘Šå·²ä¿å­˜ï¼š{outputFile}")


# ==================== ä¸»å‡½æ•° ====================


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¿«é€Ÿæ£€ç´¢è¯„æµ‹ç³»ç»Ÿ")
    parser.add_argument(
        "--mode",
        type=str,
        default="basic",
        choices=["basic", "optimized"],
        help="è¯„æµ‹æ¨¡å¼ï¼šbasicï¼ˆé»˜è®¤ï¼‰æˆ– optimizedï¼ˆå¤šç­–ç•¥å¯¹æ¯”ï¼Œç›®æ ‡ Recall@5 > 60%ï¼‰",
    )
    parser.add_argument(
        "--num-queries", type=int, default=20, help="æŠ½æ ·æŸ¥è¯¢æ•°é‡ï¼ˆé»˜è®¤ 20ï¼‰"
    )
    parser.add_argument(
        "--all-queries", action="store_true", help="ä½¿ç”¨å…¨éƒ¨æŸ¥è¯¢ï¼ˆä¸æŠ½æ ·ï¼‰"
    )
    parser.add_argument(
        "--methods",
        type=str,
        nargs="+",
        choices=_ALL_METHODS,
        help="æ‰‹åŠ¨æŒ‡å®šè¯„æµ‹æ–¹æ³•åˆ—è¡¨ï¼ˆè¦†ç›– --mode çš„é»˜è®¤é›†åˆï¼‰",
    )
    parser.add_argument(
        "--topk", type=int, default=10, help="è¯„ä¼°çš„ TopK å€¼ï¼ˆé»˜è®¤ 10ï¼‰"
    )
    parser.add_argument("--output", type=str, help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    # è¿è¡Œè¯„æµ‹
    metrics = runEval(
        methods=args.methods,
        mode=args.mode,
        numQueries=args.num_queries,
        allQueries=args.all_queries,
        topK=args.topk,
    )

    # ä¿å­˜æŠ¥å‘Š
    if metrics and args.output:
        saveReport(metrics, args.output)
    elif metrics:
        defaultOutput = os.path.join(
            config.PROJECT_ROOT, "outputs", "reports", f"quick_eval_{args.mode}.json"
        )
        saveReport(metrics, defaultOutput)


if __name__ == "__main__":
    main()
