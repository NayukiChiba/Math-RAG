"""
ç«¯åˆ°ç«¯ RAG é—®ç­”æµç¨‹æ¨¡å—

åŠŸèƒ½ï¼š
1. æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢ï¼Œæ£€ç´¢ç›¸å…³æœ¯è¯­ï¼Œæ‹¼æ¥ä¸Šä¸‹æ–‡ï¼ŒQwen ç”Ÿæˆå›ç­”
2. æ”¯æŒå•æ¡æŸ¥è¯¢å’Œæ‰¹é‡æŸ¥è¯¢
3. æ”¯æŒæ£€ç´¢ç­–ç•¥åˆ‡æ¢ï¼ˆBM25 / å‘é‡ / æ··åˆï¼‰
4. è¾“å‡ºç»“æ„åŒ–ç»“æœï¼ˆqueryã€retrieved_termsã€answerã€sourcesã€latencyï¼‰
5. å¼‚å¸¸å¤„ç†ï¼ˆæ£€ç´¢ä¸ºç©ºæ—¶ç»™å‡ºæç¤ºè€Œéå´©æºƒï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    from generation.ragPipeline import RagPipeline

    # åˆå§‹åŒ–
    pipeline = RagPipeline()

    # å•æ¡æŸ¥è¯¢
    result = pipeline.query("ä»€ä¹ˆæ˜¯ä¸€è‡´æ”¶æ•›ï¼Ÿ")
    print(result["answer"])

    # æ‰¹é‡æŸ¥è¯¢
    results = pipeline.batchQuery(["é—®é¢˜1", "é—®é¢˜2"])
"""

import json
import os
import sys
import time
from pathlib import Path
from typing import Any, Literal

# è·¯å¾„è°ƒæ•´
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

import config
from generation.promptTemplates import buildMessages
from generation.qwenInference import QwenInference
from retrieval.retrievers import BM25Retriever, HybridRetriever, VectorRetriever

# æ£€ç´¢ç­–ç•¥ç±»å‹
RetrievalStrategy = Literal["bm25", "vector", "hybrid"]


class RagPipeline:
    """ç«¯åˆ°ç«¯ RAG é—®ç­”æµç¨‹"""

    def __init__(
        self,
        strategy: RetrievalStrategy = "hybrid",
        topK: int = 5,
        corpusFile: str | None = None,
        bm25IndexFile: str | None = None,
        vectorIndexFile: str | None = None,
        vectorEmbeddingFile: str | None = None,
        modelName: str = "paraphrase-multilingual-MiniLM-L12-v2",
        hybridAlpha: float = 0.5,
        hybridBeta: float = 0.5,
    ):
        """
        åˆå§‹åŒ– RAG æµç¨‹

        Args:
            strategy: æ£€ç´¢ç­–ç•¥ï¼ˆbm25 / vector / hybridï¼‰
            topK: æ£€ç´¢è¿”å›çš„ç»“æœæ•°é‡
            corpusFile: è¯­æ–™æ–‡ä»¶è·¯å¾„
            bm25IndexFile: BM25 ç´¢å¼•æ–‡ä»¶è·¯å¾„
            vectorIndexFile: å‘é‡ç´¢å¼•æ–‡ä»¶è·¯å¾„
            vectorEmbeddingFile: å‘é‡åµŒå…¥æ–‡ä»¶è·¯å¾„
            modelName: Sentence Transformer æ¨¡å‹åç§°
            hybridAlpha: æ··åˆæ£€ç´¢ BM25 æƒé‡
            hybridBeta: æ··åˆæ£€ç´¢å‘é‡æƒé‡
        """
        self.strategy = strategy
        self.topK = topK
        self.modelName = modelName
        self.hybridAlpha = hybridAlpha
        self.hybridBeta = hybridBeta

        # é»˜è®¤è·¯å¾„
        retrievalDir = os.path.join(config.PROCESSED_DIR, "retrieval")
        self.corpusFile = corpusFile or os.path.join(retrievalDir, "corpus.jsonl")
        self.bm25IndexFile = bm25IndexFile or os.path.join(
            retrievalDir, "bm25_index.pkl"
        )
        self.vectorIndexFile = vectorIndexFile or os.path.join(
            retrievalDir, "vector_index.faiss"
        )
        self.vectorEmbeddingFile = vectorEmbeddingFile or os.path.join(
            retrievalDir, "vector_embeddings.npz"
        )

        # å»¶è¿ŸåŠ è½½
        self._retriever = None
        self._qwen = None
        self._corpus = None

    def _loadCorpus(self) -> dict[str, dict[str, Any]]:
        """åŠ è½½è¯­æ–™æ–‡ä»¶ï¼Œæ„å»º doc_id åˆ°æ–‡æ¡£çš„æ˜ å°„"""
        if self._corpus is not None:
            return self._corpus

        self._corpus = {}
        if os.path.exists(self.corpusFile):
            with open(self.corpusFile, encoding="utf-8") as f:
                for lineNum, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        doc = json.loads(line)
                        docId = doc.get("doc_id")
                        if docId:
                            self._corpus[docId] = doc
                        else:
                            print(f"âš ï¸ è¯­æ–™ç¬¬ {lineNum} è¡Œç¼ºå°‘ doc_idï¼Œå·²è·³è¿‡")
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ è¯­æ–™ç¬¬ {lineNum} è¡Œ JSON è§£æå¤±è´¥: {e}")
        return self._corpus

    def _initRetriever(self) -> None:
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        if self._retriever is not None:
            return

        print(f"ğŸ”§ åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆç­–ç•¥: {self.strategy}ï¼‰...")

        if self.strategy == "bm25":
            self._retriever = BM25Retriever(self.corpusFile, self.bm25IndexFile)
            if not self._retriever.loadIndex():
                print("BM25 ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
                self._retriever.buildIndex()
                self._retriever.saveIndex()

        elif self.strategy == "vector":
            self._retriever = VectorRetriever(
                self.corpusFile,
                self.modelName,
                self.vectorIndexFile,
                self.vectorEmbeddingFile,
            )
            if not self._retriever.loadIndex():
                print("å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
                self._retriever.buildIndex()
                self._retriever.saveIndex()

        elif self.strategy == "hybrid":
            self._retriever = HybridRetriever(
                self.corpusFile,
                self.bm25IndexFile,
                self.vectorIndexFile,
                self.vectorEmbeddingFile,
                self.modelName,
            )

        else:
            raise ValueError(
                f"ä¸æ”¯æŒçš„æ£€ç´¢ç­–ç•¥: {self.strategy}ï¼Œ"
                f"è¯·åœ¨ ['bm25', 'vector', 'hybrid'] ä¸­é€‰æ‹©"
            )

        print("æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")

    def _initQwen(self) -> None:
        """åˆå§‹åŒ– Qwen æ¨ç†å®ä¾‹"""
        if self._qwen is not None:
            return

        print("åˆå§‹åŒ– Qwen æ¨ç†...")
        self._qwen = QwenInference()
        print("Qwen åˆå§‹åŒ–å®Œæˆ")

    def _retrieve(self, queryText: str) -> list[dict[str, Any]]:
        """
        æ‰§è¡Œæ£€ç´¢

        Args:
            queryText: æŸ¥è¯¢æ–‡æœ¬

        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        self._initRetriever()

        if self.strategy == "hybrid":
            results = self._retriever.search(
                queryText,
                topK=self.topK,
                strategy="weighted",
                alpha=self.hybridAlpha,
                beta=self.hybridBeta,
            )
        else:
            results = self._retriever.search(queryText, topK=self.topK)

        return results

    def _enrichResults(self, results: list[dict[str, Any]]) -> list[dict[str, Any]]:
        """
        è¡¥å……æ£€ç´¢ç»“æœçš„å®Œæ•´æ–‡æœ¬ä¿¡æ¯

        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨

        Returns:
            è¡¥å……åçš„ç»“æœåˆ—è¡¨
        """
        corpus = self._loadCorpus()
        enriched = []

        for r in results:
            docId = r.get("doc_id")
            if docId and docId in corpus:
                doc = corpus[docId]
                enriched.append(
                    {
                        "rank": r.get("rank"),
                        "doc_id": docId,
                        "term": doc.get("term", r.get("term", "")),
                        "subject": doc.get("subject", r.get("subject", "")),
                        "text": doc.get("text", ""),
                        "source": doc.get("source", r.get("source", "")),
                        "page": doc.get("page", r.get("page")),
                        "score": r.get("score", 0.0),
                    }
                )
            else:
                enriched.append(r)

        return enriched

    def query(
        self,
        queryText: str,
        temperature: float | None = None,
        topP: float | None = None,
        maxNewTokens: int | None = None,
    ) -> dict[str, Any]:
        """
        å•æ¡æŸ¥è¯¢

        Args:
            queryText: æŸ¥è¯¢æ–‡æœ¬
            temperature: é‡‡æ ·æ¸©åº¦
            topP: top-p é‡‡æ ·å‚æ•°
            maxNewTokens: æœ€å¤§ç”Ÿæˆ token æ•°

        Returns:
            ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
                - query: åŸå§‹æŸ¥è¯¢
                - retrieved_terms: æ£€ç´¢åˆ°çš„æœ¯è¯­åˆ—è¡¨
                - answer: ç”Ÿæˆçš„å›ç­”
                - sources: æ¥æºåˆ—è¡¨
                - latency: è€—æ—¶ä¿¡æ¯
        """
        result = {
            "query": queryText,
            "retrieved_terms": [],
            "answer": "",
            "sources": [],
            "latency": {
                "retrieval_ms": 0,
                "generation_ms": 0,
                "total_ms": 0,
            },
        }

        totalStart = time.time()

        # æ£€ç´¢é˜¶æ®µ
        retrievalStart = time.time()
        try:
            rawResults = self._retrieve(queryText)
            retrievalResults = self._enrichResults(rawResults)
        except Exception as e:
            print(f"æ£€ç´¢å¤±è´¥: {e}")
            retrievalResults = []

        retrievalEnd = time.time()
        result["latency"]["retrieval_ms"] = int((retrievalEnd - retrievalStart) * 1000)

        # è®°å½•æ£€ç´¢åˆ°çš„æœ¯è¯­
        result["retrieved_terms"] = [
            {
                "term": r.get("term", ""),
                "subject": r.get("subject", ""),
                "source": r.get("source", ""),
                "page": r.get("page"),
                "score": r.get("score", 0.0),
            }
            for r in retrievalResults
        ]

        # è®°å½•æ¥æº
        result["sources"] = [
            {
                "source": r.get("source", ""),
                "page": r.get("page"),
            }
            for r in retrievalResults
            if r.get("source")
        ]

        # ç”Ÿæˆé˜¶æ®µ
        generationStart = time.time()
        try:
            self._initQwen()

            # æ„å»º messages
            messages = buildMessages(
                query=queryText,
                retrievalResults=retrievalResults if retrievalResults else None,
            )

            # ç”Ÿæˆå›ç­”
            answer = self._qwen.generateFromMessages(
                messages=messages,
                temperature=temperature,
                topP=topP,
                maxNewTokens=maxNewTokens,
            )
            result["answer"] = answer

        except Exception as e:
            print(f"ç”Ÿæˆå¤±è´¥: {e}")
            result["answer"] = f"ç”Ÿæˆå¤±è´¥: {e}"

        generationEnd = time.time()
        result["latency"]["generation_ms"] = int(
            (generationEnd - generationStart) * 1000
        )

        totalEnd = time.time()
        result["latency"]["total_ms"] = int((totalEnd - totalStart) * 1000)

        return result

    def batchQuery(
        self,
        queries: list[str],
        temperature: float | None = None,
        topP: float | None = None,
        maxNewTokens: int | None = None,
        showProgress: bool = True,
    ) -> list[dict[str, Any]]:
        """
        æ‰¹é‡æŸ¥è¯¢

        Args:
            queries: æŸ¥è¯¢æ–‡æœ¬åˆ—è¡¨
            temperature: é‡‡æ ·æ¸©åº¦
            topP: top-p é‡‡æ ·å‚æ•°
            maxNewTokens: æœ€å¤§ç”Ÿæˆ token æ•°
            showProgress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            ç»“æœåˆ—è¡¨
        """
        results = []
        total = len(queries)

        for i, q in enumerate(queries):
            if showProgress:
                print(f"å¤„ç†æŸ¥è¯¢ {i + 1}/{total}: {q[:30]}...")

            result = self.query(
                q,
                temperature=temperature,
                topP=topP,
                maxNewTokens=maxNewTokens,
            )
            results.append(result)

        return results

    def setStrategy(self, strategy: RetrievalStrategy) -> None:
        """
        åˆ‡æ¢æ£€ç´¢ç­–ç•¥

        Args:
            strategy: æ–°çš„æ£€ç´¢ç­–ç•¥
        """
        if strategy != self.strategy:
            self.strategy = strategy
            self._retriever = None  # é‡ç½®æ£€ç´¢å™¨
            print(f"æ£€ç´¢ç­–ç•¥å·²åˆ‡æ¢ä¸º: {strategy}")


def saveResults(results: list[dict[str, Any]], outputFile: str) -> None:
    """
    ä¿å­˜ç»“æœåˆ° JSONL æ–‡ä»¶

    Args:
        results: ç»“æœåˆ—è¡¨
        outputFile: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    dirname = os.path.dirname(outputFile)
    if dirname:
        os.makedirs(dirname, exist_ok=True)

    with open(outputFile, "w", encoding="utf-8") as f:
        for r in results:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"ç»“æœå·²ä¿å­˜: {outputFile}")


def loadQueries(filepath: str) -> list[str]:
    """
    ä»æ–‡ä»¶åŠ è½½æŸ¥è¯¢

    Args:
        filepath: æŸ¥è¯¢æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªæŸ¥è¯¢ï¼Œæˆ– JSONL æ ¼å¼ï¼‰

    Returns:
        æŸ¥è¯¢åˆ—è¡¨
    """
    queries = []
    skippedCount = 0

    with open(filepath, encoding="utf-8") as f:
        for lineNum, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue

            # å°è¯•è§£æä¸º JSON
            try:
                data = json.loads(line)
                if isinstance(data, dict) and "query" in data:
                    queries.append(data["query"])
                elif isinstance(data, str):
                    queries.append(data)
                else:
                    # JSON å¯¹è±¡ä½†ç¼ºå°‘ query å­—æ®µ
                    skippedCount += 1
                    print(f"âš ï¸ ç¬¬ {lineNum} è¡Œ: JSON å¯¹è±¡ç¼ºå°‘ 'query' å­—æ®µï¼Œå·²è·³è¿‡")
            except json.JSONDecodeError:
                # çº¯æ–‡æœ¬æ ¼å¼
                queries.append(line)

    if skippedCount > 0:
        print(f"âš ï¸ å…±è·³è¿‡ {skippedCount} è¡Œæ ¼å¼ä¸æ­£ç¡®çš„è®°å½•")

    return queries


# ---- å‘½ä»¤è¡Œæµ‹è¯• ----


def _testPipeline() -> None:
    """æ¨¡å—çº§æµ‹è¯•"""
    print("=" * 60)
    print("RAG Pipeline æµ‹è¯•")
    print("=" * 60)

    # åˆå§‹åŒ–
    pipeline = RagPipeline(strategy="hybrid", topK=3)

    # æµ‹è¯•æŸ¥è¯¢
    testQuery = "ä»€ä¹ˆæ˜¯ä¸€è‡´æ”¶æ•›ï¼Ÿ"
    print(f"\næµ‹è¯•æŸ¥è¯¢: {testQuery}")
    print("-" * 40)

    result = pipeline.query(testQuery)

    print(f"\næ£€ç´¢åˆ° {len(result['retrieved_terms'])} ä¸ªæœ¯è¯­:")
    for t in result["retrieved_terms"]:
        print(f"  - {t['term']} ({t['subject']}) [score: {t['score']:.4f}]")

    print(f"\nå›ç­”:\n{result['answer']}")

    print("\nè€—æ—¶:")
    print(f"  æ£€ç´¢: {result['latency']['retrieval_ms']} ms")
    print(f"  ç”Ÿæˆ: {result['latency']['generation_ms']} ms")
    print(f"  æ€»è®¡: {result['latency']['total_ms']} ms")


if __name__ == "__main__":
    _testPipeline()
