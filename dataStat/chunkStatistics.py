"""
æœ¯è¯­æ•°æ®ç»Ÿè®¡ä¸å¯è§†åŒ–

åŠŸèƒ½ï¼š
1. éå† data/processed/chunk/ ä¸‹æ‰€æœ‰æœ¯è¯­ JSON æ–‡ä»¶
2. ç»Ÿè®¡å­—æ®µç¼ºå¤±ç‡ã€é•¿åº¦åˆ†å¸ƒã€å­¦ç§‘è¦†ç›–ç­‰ä¿¡æ¯
3. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
4. è¾“å‡ºç»Ÿè®¡æŠ¥å‘Šåˆ° data/stats/

ä½¿ç”¨æ–¹æ³•ï¼š
    python -m dataStat.chunkStatistics
    æˆ–
    python dataStat/chunkStatistics.py
"""

import os
import sys
import json
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Any, Tuple
import warnings

# è·¯å¾„è°ƒæ•´ï¼šæ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

import config

# å¯¼å…¥å¯è§†åŒ–åº“
try:
    import matplotlib

    matplotlib.use("Agg")  # éäº¤äº’å¼åç«¯
    import matplotlib.pyplot as plt
    import matplotlib.font_manager as fm
    from matplotlib import rcParams
    import numpy as np

    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False
    warnings.warn("matplotlib æœªå®‰è£…ï¼Œå°†è·³è¿‡å¯è§†åŒ–åŠŸèƒ½")


# é…ç½®ä¸­æ–‡å­—ä½“ï¼ˆæ”¯æŒ Windows ç³»ç»Ÿï¼‰
if HAS_MATPLOTLIB:
    # å°è¯•ä½¿ç”¨å¾®è½¯é›…é»‘æˆ–å…¶ä»–ä¸­æ–‡å­—ä½“
    plt.rcParams["font.sans-serif"] = [
        "Microsoft YaHei",
        "SimHei",
        "Arial Unicode MS",
        "DejaVu Sans",
    ]
    plt.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
    plt.rcParams["figure.dpi"] = 100
    plt.rcParams["savefig.dpi"] = 300
    plt.rcParams["figure.figsize"] = (12, 8)


def loadJsonFile(filepath: str) -> Dict[str, Any]:
    """åŠ è½½ JSON æ–‡ä»¶"""
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {filepath}, é”™è¯¯: {e}")
        return None


def calculateFieldStats(data: Dict[str, Any], fieldName: str, fieldStats: Dict) -> None:
    """è®¡ç®—å•ä¸ªå­—æ®µçš„ç»Ÿè®¡ä¿¡æ¯"""
    if fieldName in data and data[fieldName]:
        fieldStats["present"] += 1
        value = data[fieldName]

        # è®°å½•é•¿åº¦ä¿¡æ¯
        if isinstance(value, str):
            fieldStats["lengths"].append(len(value))
        elif isinstance(value, list):
            fieldStats["lengths"].append(len(value))
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œç»Ÿè®¡åˆ—è¡¨ä¸­å…ƒç´ çš„é•¿åº¦
            if value and isinstance(value[0], str):
                for item in value:
                    fieldStats["itemLengths"].append(len(item))
            elif value and isinstance(value[0], dict):
                fieldStats["itemCounts"].append(len(value))
    else:
        fieldStats["missing"] += 1


def analyzeDefinitions(definitions: List[Dict]) -> Dict:
    """åˆ†æ definitions å­—æ®µçš„è¯¦ç»†ä¿¡æ¯"""
    if not definitions:
        return {}

    stats = {
        "count": len(definitions),
        "types": Counter(),
        "textLengths": [],
        "hasConditions": 0,
        "hasNotation": 0,
        "hasReference": 0,
    }

    for defn in definitions:
        if isinstance(defn, dict):
            stats["types"][defn.get("type", "unknown")] += 1
            if defn.get("text"):
                stats["textLengths"].append(len(defn["text"]))
            if defn.get("conditions"):
                stats["hasConditions"] += 1
            if defn.get("notation"):
                stats["hasNotation"] += 1
            if defn.get("reference"):
                stats["hasReference"] += 1

    return stats


def buildStatistics(chunkDir: str) -> Dict[str, Any]:
    """æ„å»ºå®Œæ•´çš„ç»Ÿè®¡ä¿¡æ¯"""

    # ç»Ÿè®¡ç»“æœç»“æ„
    stats = {
        "summary": {
            "totalFiles": 0,
            "validFiles": 0,
            "invalidFiles": 0,
            "totalTerms": 0,
        },
        "byBook": defaultdict(
            lambda: {
                "count": 0,
                "subjects": Counter(),
            }
        ),
        "bySubject": Counter(),
        "fields": {},
        "definitions": {
            "totalCount": 0,
            "types": Counter(),
            "textLengths": [],
            "hasConditions": 0,
            "hasNotation": 0,
            "hasReference": 0,
        },
        "termLengths": [],
        "duplicates": defaultdict(list),  # è®°å½•é‡å¤æœ¯è¯­
    }

    # å®šä¹‰éœ€è¦ç»Ÿè®¡çš„å­—æ®µ
    fieldsToCheck = [
        "id",
        "term",
        "aliases",
        "sense_id",
        "subject",
        "definitions",
        "notation",
        "formula",
        "usage",
        "applications",
        "disambiguation",
        "related_terms",
        "sources",
        "search_keys",
        "lang",
        "confidence",
    ]

    # åˆå§‹åŒ–å­—æ®µç»Ÿè®¡
    for field in fieldsToCheck:
        stats["fields"][field] = {
            "present": 0,
            "missing": 0,
            "lengths": [],
            "itemLengths": [],
            "itemCounts": [],
        }

    # éå†æ‰€æœ‰ä¹¦ç±ç›®å½•
    if not os.path.exists(chunkDir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {chunkDir}")
        return stats

    for bookName in os.listdir(chunkDir):
        bookPath = os.path.join(chunkDir, bookName)
        if not os.path.isdir(bookPath):
            continue

        print(f"ğŸ“– å¤„ç†ä¹¦ç±: {bookName}")

        # éå†è¯¥ä¹¦ç±ä¸‹çš„æ‰€æœ‰ JSON æ–‡ä»¶
        jsonFiles = [f for f in os.listdir(bookPath) if f.endswith(".json")]

        for jsonFile in jsonFiles:
            filepath = os.path.join(bookPath, jsonFile)
            stats["summary"]["totalFiles"] += 1

            # åŠ è½½ JSON
            data = loadJsonFile(filepath)
            if data is None:
                stats["summary"]["invalidFiles"] += 1
                continue

            stats["summary"]["validFiles"] += 1
            stats["summary"]["totalTerms"] += 1

            # è®°å½•ä¹¦ç±ç»Ÿè®¡
            stats["byBook"][bookName]["count"] += 1

            # ç»Ÿè®¡å­¦ç§‘
            subject = data.get("subject", "unknown")
            stats["bySubject"][subject] += 1
            stats["byBook"][bookName]["subjects"][subject] += 1

            # ç»Ÿè®¡æœ¯è¯­é•¿åº¦
            term = data.get("term", "")
            if term:
                stats["termLengths"].append(len(term))
                # æ£€æŸ¥é‡å¤æœ¯è¯­
                stats["duplicates"][term].append(
                    {"book": bookName, "file": jsonFile, "subject": subject}
                )

            # ç»Ÿè®¡å„å­—æ®µ
            for field in fieldsToCheck:
                calculateFieldStats(data, field, stats["fields"][field])

            # ç‰¹æ®Šå¤„ç†ï¼šdefinitions çš„è¯¦ç»†ç»Ÿè®¡
            definitions = data.get("definitions", [])
            if definitions:
                defStats = analyzeDefinitions(definitions)
                if defStats:
                    stats["definitions"]["totalCount"] += defStats["count"]
                    stats["definitions"]["types"].update(defStats["types"])
                    stats["definitions"]["textLengths"].extend(defStats["textLengths"])
                    stats["definitions"]["hasConditions"] += defStats["hasConditions"]
                    stats["definitions"]["hasNotation"] += defStats["hasNotation"]
                    stats["definitions"]["hasReference"] += defStats["hasReference"]

    # æ‰¾å‡ºçœŸæ­£çš„é‡å¤æœ¯è¯­ï¼ˆå‡ºç°åœ¨å¤šä¸ªåœ°æ–¹ï¼‰
    actualDuplicates = {
        term: locations
        for term, locations in stats["duplicates"].items()
        if len(locations) > 1
    }
    stats["duplicates"] = actualDuplicates

    return stats


def calculatePercentiles(
    values: List[float], percentiles: List[int] = [25, 50, 75, 90, 95, 99]
) -> Dict:
    """è®¡ç®—ç™¾åˆ†ä½æ•°"""
    if not values:
        return {}

    sortedValues = sorted(values)
    n = len(sortedValues)

    result = {
        "min": sortedValues[0],
        "max": sortedValues[-1],
        "mean": sum(sortedValues) / n,
    }

    for p in percentiles:
        idx = int(n * p / 100)
        if idx >= n:
            idx = n - 1
        result[f"p{p}"] = sortedValues[idx]

    return result


def formatStatistics(stats: Dict[str, Any]) -> Dict[str, Any]:
    """æ ¼å¼åŒ–ç»Ÿè®¡ç»“æœï¼Œä½¿å…¶æ›´æ˜“è¯»"""

    formatted = {
        "meta": {
            "generatedAt": "2026-02-14",
            "description": "æ•°å­¦æœ¯è¯­ JSON æ•°æ®ç»Ÿè®¡æŠ¥å‘Š",
            "version": "2.0",
        },
        "summary": stats["summary"],
        "byBook": {},
        "bySubject": dict(stats["bySubject"]),
        "fieldCoverage": {},
        "fieldLengthDistribution": {},
        "definitionsAnalysis": {},
        "termLengthDistribution": {},
        "duplicates": {
            "count": len(stats["duplicates"]),
            "details": stats["duplicates"],
        },
    }

    # è½¬æ¢ byBookï¼ˆå¤„ç† defaultdict å’Œ Counterï¼‰
    for book, bookStats in stats["byBook"].items():
        formatted["byBook"][book] = {
            "count": bookStats["count"],
            "subjects": dict(bookStats["subjects"]),
        }

    # å­—æ®µè¦†ç›–ç‡ç»Ÿè®¡
    total = stats["summary"]["validFiles"]
    for field, fieldStats in stats["fields"].items():
        formatted["fieldCoverage"][field] = {
            "present": fieldStats["present"],
            "missing": fieldStats["missing"],
            "coverageRate": round(fieldStats["present"] / total * 100, 2)
            if total > 0
            else 0,
        }

    # å­—æ®µé•¿åº¦åˆ†å¸ƒç»Ÿè®¡
    for field, fieldStats in stats["fields"].items():
        if fieldStats["lengths"]:
            formatted["fieldLengthDistribution"][field] = calculatePercentiles(
                fieldStats["lengths"]
            )

        # å¯¹äºåˆ—è¡¨ç±»å‹å­—æ®µï¼Œç»Ÿè®¡å…ƒç´ æ•°é‡åˆ†å¸ƒ
        if fieldStats["itemCounts"]:
            formatted["fieldLengthDistribution"][f"{field}Count"] = (
                calculatePercentiles(fieldStats["itemCounts"])
            )

    # definitions åˆ†æ
    formatted["definitionsAnalysis"] = {
        "totalDefinitions": stats["definitions"]["totalCount"],
        "avgPerTerm": round(stats["definitions"]["totalCount"] / total, 2)
        if total > 0
        else 0,
        "types": dict(stats["definitions"]["types"]),
        "textLength": calculatePercentiles(stats["definitions"]["textLengths"])
        if stats["definitions"]["textLengths"]
        else {},
        "withConditions": stats["definitions"]["hasConditions"],
        "withNotation": stats["definitions"]["hasNotation"],
        "withReference": stats["definitions"]["hasReference"],
    }

    # æœ¯è¯­é•¿åº¦åˆ†å¸ƒ
    formatted["termLengthDistribution"] = (
        calculatePercentiles(stats["termLengths"]) if stats["termLengths"] else {}
    )

    return formatted


def createVisualization(stats: Dict[str, Any], outputDir: str) -> None:
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    if not HAS_MATPLOTLIB:
        print("âš ï¸  è·³è¿‡å¯è§†åŒ–ï¼šmatplotlib æœªå®‰è£…")
        return

    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    vizDir = os.path.join(outputDir, "visualizations")
    os.makedirs(vizDir, exist_ok=True)

    # 1. ä¹¦ç±æœ¯è¯­åˆ†å¸ƒæŸ±çŠ¶å›¾
    createBookDistributionChart(stats, vizDir)

    # 2. å­¦ç§‘åˆ†å¸ƒé¥¼å›¾
    createSubjectDistributionChart(stats, vizDir)

    # 3. å­—æ®µè¦†ç›–ç‡çƒ­åŠ›å›¾
    createFieldCoverageChart(stats, vizDir)

    # 4. æœ¯è¯­é•¿åº¦åˆ†å¸ƒç›´æ–¹å›¾
    createTermLengthDistribution(stats, vizDir)

    # 5. å®šä¹‰ç±»å‹åˆ†å¸ƒ
    createDefinitionTypeChart(stats, vizDir)

    # 6. ç»¼åˆç»Ÿè®¡é¢æ¿
    createComprehensiveDashboard(stats, vizDir)

    print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {vizDir}")


def createBookDistributionChart(stats: Dict[str, Any], outputDir: str) -> None:
    """ä¹¦ç±æœ¯è¯­åˆ†å¸ƒæŸ±çŠ¶å›¾"""
    try:
        fig, ax = plt.subplots(figsize=(12, 6))

        books = list(stats["byBook"].keys())
        counts = [stats["byBook"][book]["count"] for book in books]

        # ç®€åŒ–ä¹¦åæ˜¾ç¤º
        shortNames = [
            book.replace("(ç¬¬5ç‰ˆ)", "").replace("(ç¬¬äº”ç‰ˆ)", "").replace("ç¬¬ä¸‰ç‰ˆ", "")
            for book in books
        ]

        colors = plt.cm.Set3(range(len(books)))
        bars = ax.bar(
            range(len(books)), counts, color=colors, edgecolor="black", linewidth=1.2
        )

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars:
            height = bar.get_height()
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height,
                f"{int(height)}",
                ha="center",
                va="bottom",
                fontsize=12,
                fontweight="bold",
            )

        ax.set_xlabel("æ•™æåç§°", fontsize=14, fontweight="bold")
        ax.set_ylabel("æœ¯è¯­æ•°é‡", fontsize=14, fontweight="bold")
        ax.set_title("å„æ•™ææœ¯è¯­æ•°é‡åˆ†å¸ƒ", fontsize=16, fontweight="bold", pad=20)
        ax.set_xticks(range(len(books)))
        ax.set_xticklabels(shortNames, rotation=15, ha="right", fontsize=10)
        ax.grid(axis="y", alpha=0.3, linestyle="--")

        plt.tight_layout()
        plt.savefig(os.path.join(outputDir, "1_ä¹¦ç±æœ¯è¯­åˆ†å¸ƒ.png"), bbox_inches="tight")
        plt.close()

        print("  âœ“ ä¹¦ç±æœ¯è¯­åˆ†å¸ƒå›¾")
    except Exception as e:
        print(f"  âœ— ä¹¦ç±æœ¯è¯­åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")


def createSubjectDistributionChart(stats: Dict[str, Any], outputDir: str) -> None:
    """å­¦ç§‘åˆ†å¸ƒé¥¼å›¾"""
    try:
        fig, ax = plt.subplots(figsize=(10, 8))

        subjects = list(stats["bySubject"].keys())
        counts = [stats["bySubject"][s] for s in subjects]

        # è¿‡æ»¤æ‰æ‹¼å†™é”™è¯¯çš„å­¦ç§‘
        filteredData = [(s, c) for s, c in zip(subjects, counts) if c > 10]
        subjects, counts = zip(*filteredData) if filteredData else ([], [])

        colors = plt.cm.Pastel1(range(len(subjects)))
        explode = [0.05] * len(subjects)  # åˆ†ç¦»é¥¼å›¾

        wedges, texts, autotexts = ax.pie(
            counts,
            labels=subjects,
            autopct="%1.1f%%",
            colors=colors,
            explode=explode,
            startangle=90,
            textprops={"fontsize": 12, "fontweight": "bold"},
        )

        # æ·»åŠ æ•°é‡æ ‡æ³¨
        for i, (subject, count) in enumerate(zip(subjects, counts)):
            texts[i].set_text(f"{subject}\n({count}ä¸ª)")

        ax.set_title("å­¦ç§‘æœ¯è¯­åˆ†å¸ƒ", fontsize=16, fontweight="bold", pad=20)

        plt.tight_layout()
        plt.savefig(os.path.join(outputDir, "2_å­¦ç§‘åˆ†å¸ƒ.png"), bbox_inches="tight")
        plt.close()

        print("  âœ“ å­¦ç§‘åˆ†å¸ƒå›¾")
    except Exception as e:
        print(f"  âœ— å­¦ç§‘åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")


def createFieldCoverageChart(stats: Dict[str, Any], outputDir: str) -> None:
    """å­—æ®µè¦†ç›–ç‡æ¨ªå‘æŸ±çŠ¶å›¾"""
    try:
        fig, ax = plt.subplots(figsize=(12, 8))

        # è®¡ç®—è¦†ç›–ç‡
        total = stats["summary"]["validFiles"]
        fieldNames = []
        coverageRates = []

        for field, fieldStats in stats["fields"].items():
            rate = fieldStats["present"] / total * 100 if total > 0 else 0
            fieldNames.append(field)
            coverageRates.append(rate)

        # æ’åº
        sortedData = sorted(
            zip(fieldNames, coverageRates), key=lambda x: x[1], reverse=True
        )
        fieldNames, coverageRates = zip(*sortedData)

        # é¢œè‰²ç¼–ç ï¼š>95% ç»¿è‰²ï¼Œ90-95% é»„è‰²ï¼Œ<90% çº¢è‰²
        colors = [
            "#2ecc71" if r >= 95 else "#f39c12" if r >= 90 else "#e74c3c"
            for r in coverageRates
        ]

        bars = ax.barh(
            range(len(fieldNames)),
            coverageRates,
            color=colors,
            edgecolor="black",
            linewidth=1,
        )

        # æ·»åŠ ç™¾åˆ†æ¯”æ ‡ç­¾
        for i, (bar, rate) in enumerate(zip(bars, coverageRates)):
            ax.text(
                rate + 1,
                bar.get_y() + bar.get_height() / 2,
                f"{rate:.1f}%",
                ha="left",
                va="center",
                fontsize=10,
                fontweight="bold",
            )

        ax.set_xlabel("è¦†ç›–ç‡ (%)", fontsize=14, fontweight="bold")
        ax.set_ylabel("å­—æ®µåç§°", fontsize=14, fontweight="bold")
        ax.set_title("å­—æ®µè¦†ç›–ç‡ç»Ÿè®¡", fontsize=16, fontweight="bold", pad=20)
        ax.set_yticks(range(len(fieldNames)))
        ax.set_yticklabels(fieldNames, fontsize=10)
        ax.set_xlim(0, 105)
        ax.grid(axis="x", alpha=0.3, linestyle="--")
        ax.axvline(
            x=95,
            color="green",
            linestyle="--",
            alpha=0.5,
            linewidth=2,
            label="ä¼˜ç§€çº¿ (95%)",
        )
        ax.legend(loc="lower right", fontsize=10)

        plt.tight_layout()
        plt.savefig(os.path.join(outputDir, "3_å­—æ®µè¦†ç›–ç‡.png"), bbox_inches="tight")
        plt.close()

        print("  âœ“ å­—æ®µè¦†ç›–ç‡å›¾")
    except Exception as e:
        print(f"  âœ— å­—æ®µè¦†ç›–ç‡å›¾ç”Ÿæˆå¤±è´¥: {e}")


def createTermLengthDistribution(stats: Dict[str, Any], outputDir: str) -> None:
    """æœ¯è¯­é•¿åº¦åˆ†å¸ƒç›´æ–¹å›¾"""
    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

        # æœ¯è¯­é•¿åº¦åˆ†å¸ƒ
        termLengths = stats["termLengths"]
        ax1.hist(
            termLengths,
            bins=range(0, max(termLengths) + 2),
            edgecolor="black",
            color="skyblue",
            alpha=0.7,
        )
        ax1.axvline(
            np.mean(termLengths),
            color="red",
            linestyle="--",
            linewidth=2,
            label=f"å¹³å‡å€¼: {np.mean(termLengths):.1f}",
        )
        ax1.axvline(
            np.median(termLengths),
            color="green",
            linestyle="--",
            linewidth=2,
            label=f"ä¸­ä½æ•°: {np.median(termLengths):.1f}",
        )
        ax1.set_xlabel("æœ¯è¯­é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰", fontsize=12, fontweight="bold")
        ax1.set_ylabel("æœ¯è¯­æ•°é‡", fontsize=12, fontweight="bold")
        ax1.set_title("æœ¯è¯­é•¿åº¦åˆ†å¸ƒ", fontsize=14, fontweight="bold")
        ax1.legend(fontsize=10)
        ax1.grid(alpha=0.3, linestyle="--")

        # å®šä¹‰æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ
        defLengths = stats["definitions"]["textLengths"]
        ax2.hist(defLengths, bins=50, edgecolor="black", color="lightcoral", alpha=0.7)
        ax2.axvline(
            np.mean(defLengths),
            color="red",
            linestyle="--",
            linewidth=2,
            label=f"å¹³å‡å€¼: {np.mean(defLengths):.0f}",
        )
        ax2.axvline(
            np.median(defLengths),
            color="green",
            linestyle="--",
            linewidth=2,
            label=f"ä¸­ä½æ•°: {np.median(defLengths):.0f}",
        )
        ax2.set_xlabel("å®šä¹‰æ–‡æœ¬é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰", fontsize=12, fontweight="bold")
        ax2.set_ylabel("å®šä¹‰æ•°é‡", fontsize=12, fontweight="bold")
        ax2.set_title("å®šä¹‰æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ", fontsize=14, fontweight="bold")
        ax2.legend(fontsize=10)
        ax2.grid(alpha=0.3, linestyle="--")

        plt.tight_layout()
        plt.savefig(os.path.join(outputDir, "4_é•¿åº¦åˆ†å¸ƒ.png"), bbox_inches="tight")
        plt.close()

        print("  âœ“ é•¿åº¦åˆ†å¸ƒå›¾")
    except Exception as e:
        print(f"  âœ— é•¿åº¦åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")


def createDefinitionTypeChart(stats: Dict[str, Any], outputDir: str) -> None:
    """å®šä¹‰ç±»å‹åˆ†å¸ƒå›¾"""
    try:
        fig, ax = plt.subplots(figsize=(10, 6))

        types = list(stats["definitions"]["types"].keys())
        counts = [stats["definitions"]["types"][t] for t in types]

        colors = plt.cm.Set2(range(len(types)))
        bars = ax.bar(types, counts, color=colors, edgecolor="black", linewidth=1.2)

        # æ·»åŠ æ•°å€¼å’Œç™¾åˆ†æ¯”æ ‡ç­¾
        total = sum(counts)
        for bar in bars:
            height = bar.get_height()
            percentage = height / total * 100
            ax.text(
                bar.get_x() + bar.get_width() / 2.0,
                height,
                f"{int(height)}\n({percentage:.1f}%)",
                ha="center",
                va="bottom",
                fontsize=11,
                fontweight="bold",
            )

        ax.set_xlabel("å®šä¹‰ç±»å‹", fontsize=14, fontweight="bold")
        ax.set_ylabel("å®šä¹‰æ•°é‡", fontsize=14, fontweight="bold")
        ax.set_title("å®šä¹‰ç±»å‹åˆ†å¸ƒ", fontsize=16, fontweight="bold", pad=20)
        ax.grid(axis="y", alpha=0.3, linestyle="--")

        plt.tight_layout()
        plt.savefig(os.path.join(outputDir, "5_å®šä¹‰ç±»å‹åˆ†å¸ƒ.png"), bbox_inches="tight")
        plt.close()

        print("  âœ“ å®šä¹‰ç±»å‹åˆ†å¸ƒå›¾")
    except Exception as e:
        print(f"  âœ— å®šä¹‰ç±»å‹åˆ†å¸ƒå›¾ç”Ÿæˆå¤±è´¥: {e}")


def createComprehensiveDashboard(stats: Dict[str, Any], outputDir: str) -> None:
    """ç»¼åˆç»Ÿè®¡é¢æ¿"""
    try:
        fig = plt.figure(figsize=(20, 12))
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

        # 1. æ€»ä½“ç»Ÿè®¡æ–‡æœ¬
        ax1 = fig.add_subplot(gs[0, :])
        ax1.axis("off")
        summaryText = f"""
        ğŸ“Š æ•°å­¦æœ¯è¯­æ•°æ®ç»Ÿè®¡æŠ¥å‘Š
        
        æ€»æœ¯è¯­æ•°: {stats["summary"]["totalTerms"]:,} ä¸ª    |    æœ‰æ•ˆæ–‡ä»¶: {stats["summary"]["validFiles"]:,}    |    æ— æ•ˆæ–‡ä»¶: {stats["summary"]["invalidFiles"]}
        
        å¹³å‡æœ¯è¯­é•¿åº¦: {np.mean(stats["termLengths"]):.1f} å­—ç¬¦    |    å¹³å‡å®šä¹‰æ•°: {stats["definitions"]["totalCount"] / stats["summary"]["validFiles"]:.1f} ä¸ª/æœ¯è¯­
        """
        ax1.text(
            0.5,
            0.5,
            summaryText,
            ha="center",
            va="center",
            fontsize=14,
            fontweight="bold",
            bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5),
        )

        # 2. ä¹¦ç±åˆ†å¸ƒ
        ax2 = fig.add_subplot(gs[1, 0])
        books = list(stats["byBook"].keys())
        counts = [stats["byBook"][book]["count"] for book in books]
        shortNames = [book.split("(")[0][:8] for book in books]
        ax2.bar(range(len(books)), counts, color=plt.cm.Set3(range(len(books))))
        ax2.set_xticks(range(len(books)))
        ax2.set_xticklabels(shortNames, rotation=45, ha="right", fontsize=9)
        ax2.set_title("ä¹¦ç±åˆ†å¸ƒ", fontweight="bold")
        ax2.grid(axis="y", alpha=0.3)

        # 3. å­¦ç§‘åˆ†å¸ƒ
        ax3 = fig.add_subplot(gs[1, 1])
        subjects = [s for s, c in stats["bySubject"].items() if c > 10]
        subCounts = [stats["bySubject"][s] for s in subjects]
        ax3.pie(
            subCounts,
            labels=subjects,
            autopct="%1.1f%%",
            colors=plt.cm.Pastel1(range(len(subjects))),
        )
        ax3.set_title("å­¦ç§‘åˆ†å¸ƒ", fontweight="bold")

        # 4. å­—æ®µè¦†ç›–ç‡ TOP 10
        ax4 = fig.add_subplot(gs[1, 2])
        total = stats["summary"]["validFiles"]
        fieldRates = [
            (f, s["present"] / total * 100) for f, s in stats["fields"].items()
        ]
        fieldRates.sort(key=lambda x: x[1], reverse=True)
        topFields = fieldRates[:10]
        fields, rates = zip(*topFields)
        colors = [
            "#2ecc71" if r >= 95 else "#f39c12" if r >= 90 else "#e74c3c" for r in rates
        ]
        ax4.barh(range(len(fields)), rates, color=colors)
        ax4.set_yticks(range(len(fields)))
        ax4.set_yticklabels(fields, fontsize=9)
        ax4.set_xlim(0, 105)
        ax4.set_title("å­—æ®µè¦†ç›–ç‡ TOP10", fontweight="bold")
        ax4.grid(axis="x", alpha=0.3)

        # 5. æœ¯è¯­é•¿åº¦åˆ†å¸ƒ
        ax5 = fig.add_subplot(gs[2, 0])
        ax5.hist(
            stats["termLengths"],
            bins=range(0, max(stats["termLengths"]) + 2),
            edgecolor="black",
            color="skyblue",
            alpha=0.7,
        )
        ax5.set_xlabel("æœ¯è¯­é•¿åº¦")
        ax5.set_ylabel("æ•°é‡")
        ax5.set_title("æœ¯è¯­é•¿åº¦åˆ†å¸ƒ", fontweight="bold")
        ax5.grid(alpha=0.3)

        # 6. å®šä¹‰æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ
        ax6 = fig.add_subplot(gs[2, 1])
        ax6.hist(
            stats["definitions"]["textLengths"],
            bins=50,
            edgecolor="black",
            color="lightcoral",
            alpha=0.7,
        )
        ax6.set_xlabel("å®šä¹‰æ–‡æœ¬é•¿åº¦")
        ax6.set_ylabel("æ•°é‡")
        ax6.set_title("å®šä¹‰æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ", fontweight="bold")
        ax6.grid(alpha=0.3)

        # 7. å®šä¹‰ç±»å‹åˆ†å¸ƒ
        ax7 = fig.add_subplot(gs[2, 2])
        types = list(stats["definitions"]["types"].keys())
        typeCounts = [stats["definitions"]["types"][t] for t in types]
        ax7.bar(types, typeCounts, color=plt.cm.Set2(range(len(types))))
        ax7.set_title("å®šä¹‰ç±»å‹åˆ†å¸ƒ", fontweight="bold")
        ax7.grid(axis="y", alpha=0.3)

        plt.suptitle("æ•°å­¦æœ¯è¯­æ•°æ®ç»¼åˆç»Ÿè®¡é¢æ¿", fontsize=18, fontweight="bold", y=0.98)
        plt.savefig(os.path.join(outputDir, "0_ç»¼åˆç»Ÿè®¡é¢æ¿.png"), bbox_inches="tight")
        plt.close()

        print("  âœ“ ç»¼åˆç»Ÿè®¡é¢æ¿")
    except Exception as e:
        print(f"  âœ— ç»¼åˆç»Ÿè®¡é¢æ¿ç”Ÿæˆå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print(" " * 20 + "ğŸ“Š æ•°å­¦æœ¯è¯­æ•°æ®ç»Ÿè®¡ä¸å¯è§†åŒ–")
    print("=" * 70)

    # è¾“å…¥è¾“å‡ºè·¯å¾„
    chunkDir = config.CHUNK_DIR
    statsDir = os.path.join(config.PROJECT_ROOT, "data", "stats")
    outputFile = os.path.join(statsDir, "chunkStatistics.json")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(statsDir, exist_ok=True)

    print(f"\nğŸ“‚ è¾“å…¥ç›®å½•: {chunkDir}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {statsDir}\n")

    # æ„å»ºç»Ÿè®¡ä¿¡æ¯
    print("ğŸ”„ å¼€å§‹ç»Ÿè®¡åˆ†æ...\n")
    rawStats = buildStatistics(chunkDir)

    # æ ¼å¼åŒ–ç»Ÿè®¡ç»“æœ
    print("\nğŸ”„ æ ¼å¼åŒ–ç»Ÿè®¡ç»“æœ...")
    formattedStats = formatStatistics(rawStats)

    # ä¿å­˜åˆ°æ–‡ä»¶
    print(f"ğŸ’¾ ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š: {outputFile}")
    with open(outputFile, "w", encoding="utf-8") as f:
        json.dump(formattedStats, f, ensure_ascii=False, indent=2)

    # ç”Ÿæˆå¯è§†åŒ–
    createVisualization(rawStats, statsDir)

    # æ‰“å°æ‘˜è¦
    print("\n" + "=" * 70)
    print(" " * 25 + "âœ… ç»Ÿè®¡å®Œæˆï¼")
    print("=" * 70)
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"  â€¢ æ€»æ–‡ä»¶æ•°: {formattedStats['summary']['totalFiles']:,}")
    print(f"  â€¢ æœ‰æ•ˆæ–‡ä»¶: {formattedStats['summary']['validFiles']:,}")
    print(f"  â€¢ æœ¯è¯­æ€»æ•°: {formattedStats['summary']['totalTerms']:,}")

    print(f"\nğŸ“– å„ä¹¦ç±æœ¯è¯­æ•°é‡:")
    for book, bookStats in sorted(
        formattedStats["byBook"].items(), key=lambda x: x[1]["count"], reverse=True
    ):
        print(f"  â€¢ {book}: {bookStats['count']} ä¸ª")

    print(f"\nğŸ“š å­¦ç§‘åˆ†å¸ƒ:")
    for subject, count in sorted(
        formattedStats["bySubject"].items(), key=lambda x: x[1], reverse=True
    ):
        percentage = count / formattedStats["summary"]["totalTerms"] * 100
        print(f"  â€¢ {subject}: {count} ä¸ª ({percentage:.1f}%)")

    print(f"\nğŸ”„ é‡å¤æœ¯è¯­: {formattedStats['duplicates']['count']} ä¸ª")

    print(f"\nğŸ’¡ è¾“å‡ºæ–‡ä»¶:")
    print(f"  â€¢ ç»Ÿè®¡æŠ¥å‘Š: {outputFile}")
    if HAS_MATPLOTLIB:
        print(f"  â€¢ å¯è§†åŒ–å›¾è¡¨: {os.path.join(statsDir, 'visualizations')}")

    print("\n" + "=" * 70)
    print(" " * 20 + "ğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")
    print("=" * 70)


if __name__ == "__main__":
    main()
