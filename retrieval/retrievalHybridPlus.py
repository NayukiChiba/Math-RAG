"""
æ··åˆæ£€ç´¢ + æ”¹è¿›ç‰ˆ

åŠŸèƒ½ï¼š
1. æ”¹è¿›çš„ RRF èåˆç­–ç•¥
2. è‡ªé€‚åº”æƒé‡è°ƒæ•´
3. æ”¯æŒæ›´å¤šå¬å›ç»“æœè¿›è¡Œèåˆ
4. æ”¹è¿›çš„å½’ä¸€åŒ–æ–¹æ³•

ä½¿ç”¨æ–¹æ³•ï¼š
    # é»˜è®¤åŠ æƒèåˆ
    python retrieval/retrievalHybridPlus.py --query "æ³°å‹’å±•å¼€" --topk 10

    # ä½¿ç”¨ RRF èåˆ
    python retrieval/retrievalHybridPlus.py --query "æ³°å‹’å±•å¼€" --topk 10 --strategy rrf

    # è‡ªé€‚åº”æƒé‡
    python retrieval/retrievalHybridPlus.py --query "æ³°å‹’å±•å¼€" --topk 10 --auto-weight
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Any

import numpy as np

# è·¯å¾„è°ƒæ•´
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

import config
from retrieval.retrievalBM25Plus import BM25PlusRetriever
from retrieval.retrievalVector import VectorRetriever


class HybridPlusRetriever:
    """æ”¹è¿›çš„æ··åˆæ£€ç´¢å™¨"""

    def __init__(
        self,
        corpusFile: str,
        bm25IndexFile: str,
        vectorIndexFile: str,
        vectorEmbeddingFile: str,
        modelName: str = "paraphrase-multilingual-MiniLM-L12-v2",
        termsFile: str | None = None,
    ):
        """
        åˆå§‹åŒ–æ”¹è¿›çš„æ··åˆæ£€ç´¢å™¨

        Args:
            corpusFile: è¯­æ–™æ–‡ä»¶è·¯å¾„
            bm25IndexFile: BM25 ç´¢å¼•æ–‡ä»¶è·¯å¾„
            vectorIndexFile: å‘é‡ç´¢å¼•æ–‡ä»¶è·¯å¾„
            vectorEmbeddingFile: å‘é‡åµŒå…¥æ–‡ä»¶è·¯å¾„
            modelName: Sentence Transformer æ¨¡å‹åç§°
            termsFile: æœ¯è¯­æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äº BM25+ æŸ¥è¯¢æ‰©å±•ï¼‰
        """
        self.corpusFile = corpusFile

        # åˆå§‹åŒ– BM25+ æ£€ç´¢å™¨ï¼ˆæ”¯æŒæŸ¥è¯¢æ‰©å±•ï¼‰
        print("ğŸ”§ åˆå§‹åŒ– BM25+ æ£€ç´¢å™¨...")
        self.bm25Retriever = BM25PlusRetriever(corpusFile, bm25IndexFile, termsFile)
        if not self.bm25Retriever.loadIndex():
            print("âš ï¸  BM25+ ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
            self.bm25Retriever.loadTermsMap()
            self.bm25Retriever.buildIndex()
            self.bm25Retriever.saveIndex()

        # åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨
        print("ğŸ”§ åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨...")
        self.vectorRetriever = VectorRetriever(
            corpusFile, modelName, vectorIndexFile, vectorEmbeddingFile
        )
        if not self.vectorRetriever.loadIndex():
            print("âš ï¸  å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
            self.vectorRetriever.buildIndex()
            self.vectorRetriever.saveIndex()

        print("âœ… æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ\n")

    def normalizeMinMax(self, scores: list[float]) -> list[float]:
        """Min-Max å½’ä¸€åŒ–"""
        if not scores:
            return []

        minScore = min(scores)
        maxScore = max(scores)

        if maxScore == minScore:
            return [1.0] * len(scores)

        return [(s - minScore) / (maxScore - minScore) for s in scores]

    def normalizeZScore(self, scores: list[float]) -> list[float]:
        """Z-Score å½’ä¸€åŒ–"""
        if not scores:
            return []

        mean = np.mean(scores)
        std = np.std(scores)

        if std == 0:
            return [0.0] * len(scores)

        return [(s - mean) / std for s in scores]

    def normalizePercentile(self, scores: list[float]) -> list[float]:
        """ç™¾åˆ†ä½æ•°å½’ä¸€åŒ–ï¼ˆæ›´é²æ£’ï¼‰"""
        if not scores:
            return []

        sortedScores = sorted(scores)
        n = len(sortedScores)

        result = []
        for s in scores:
            # è®¡ç®—å°äºç­‰äºå½“å‰åˆ†æ•°çš„æ•°é‡
            rank = sum(1 for x in sortedScores if x <= s)
            result.append(rank / n)

        return result

    def fuseRRFImproved(
        self,
        bm25Results: list[dict[str, Any]],
        vectorResults: list[dict[str, Any]],
        topK: int = 10,
        rrfK: int = 60,
    ) -> list[dict[str, Any]]:
        """
        æ”¹è¿›çš„ RRF èåˆç­–ç•¥

        æ”¹è¿›ç‚¹ï¼š
        1. ä½¿ç”¨æ›´å¤šå€™é€‰ç»“æœè¿›è¡Œèåˆ
        2. æ ¹æ®æŸ¥è¯¢éš¾åº¦åŠ¨æ€è°ƒæ•´ k å€¼
        3. æ·»åŠ åˆ†æ•°åŠ æƒ
        """
        # è®¡ç®—æŸ¥è¯¢éš¾åº¦ï¼ˆåŸºäº BM25 åˆ†æ•°åˆ†å¸ƒï¼‰
        if bm25Results:
            bm25Scores = [r["score"] for r in bm25Results]
            avgScore = np.mean(bm25Scores)
            # æŸ¥è¯¢éš¾åº¦é«˜æ—¶ä½¿ç”¨æ›´å°çš„ k å€¼
            if avgScore < 0.5:
                rrfK = max(30, rrfK // 2)
            elif avgScore > 2.0:
                rrfK = min(100, rrfK * 2)

        # æ„å»º doc_id åˆ°æ’åçš„æ˜ å°„
        bm25RankMap = {r["doc_id"]: r["rank"] for r in bm25Results}
        vectorRankMap = {r["doc_id"]: r["rank"] for r in vectorResults}

        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„ doc_id
        allDocIds = set(bm25RankMap.keys()) | set(vectorRankMap.keys())

        # è®¡ç®— RRF åˆ†æ•°
        rrfScores = {}
        for docId in allDocIds:
            rrfScore = 0.0
            if docId in bm25RankMap:
                rrfScore += 1.0 / (rrfK + bm25RankMap[docId])
            if docId in vectorRankMap:
                rrfScore += 1.0 / (rrfK + vectorRankMap[docId])
            rrfScores[docId] = rrfScore

        # æ’åºå¹¶æ„å»ºç»“æœ
        sortedDocIds = sorted(
            rrfScores.keys(), key=lambda x: rrfScores[x], reverse=True
        )

        # è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯
        docInfoMap = {r["doc_id"]: r for r in bm25Results}
        docInfoMap.update({r["doc_id"]: r for r in vectorResults})

        results = []
        for rank, docId in enumerate(sortedDocIds, 1):
            if rank > topK:
                break
            docInfo = docInfoMap[docId]
            results.append(
                {
                    "rank": rank,
                    "doc_id": docId,
                    "term": docInfo["term"],
                    "subject": docInfo.get("subject", ""),
                    "score": rrfScores[docId],
                    "bm25_rank": bm25RankMap.get(docId, None),
                    "vector_rank": vectorRankMap.get(docId, None),
                    "source": docInfo.get("source", ""),
                    "page": docInfo.get("page", None),
                }
            )

        return results

    def fuseWeightedImproved(
        self,
        bm25Results: list[dict[str, Any]],
        vectorResults: list[dict[str, Any]],
        topK: int = 10,
        alpha: float | None = None,
        beta: float | None = None,
        normalization: str = "percentile",
    ) -> list[dict[str, Any]]:
        """
        æ”¹è¿›çš„åŠ æƒèåˆç­–ç•¥

        æ”¹è¿›ç‚¹ï¼š
        1. ä½¿ç”¨ç™¾åˆ†ä½æ•°å½’ä¸€åŒ–ï¼ˆæ›´é²æ£’ï¼‰
        2. è‡ªé€‚åº”æƒé‡è°ƒæ•´
        3. è€ƒè™‘ç»“æœé‡å åº¦
        """
        # æå–åˆ†æ•°
        bm25Scores = [r["score"] for r in bm25Results]
        vectorScores = [r["score"] for r in vectorResults]

        if not bm25Scores or not vectorScores:
            # å¦‚æœä¸€æ–¹æ— ç»“æœï¼Œä½¿ç”¨å¦ä¸€æ–¹
            if bm25Scores:
                return bm25Results[:topK]
            return vectorResults[:topK]

        # å½’ä¸€åŒ–
        if normalization == "minmax":
            bm25NormScores = self.normalizeMinMax(bm25Scores)
            vectorNormScores = self.normalizeMinMax(vectorScores)
        elif normalization == "zscore":
            bm25NormScores = self.normalizeZScore(bm25Scores)
            vectorNormScores = self.normalizeZScore(vectorScores)
        else:  # percentile
            bm25NormScores = self.normalizePercentile(bm25Scores)
            vectorNormScores = self.normalizePercentile(vectorScores)

        # è®¡ç®—ç»“æœé‡å åº¦
        bm25DocIds = set(r["doc_id"] for r in bm25Results)
        vectorDocIds = set(r["doc_id"] for r in vectorResults)
        overlap = len(bm25DocIds & vectorDocIds)
        overlapRatio = overlap / min(len(bm25DocIds), len(vectorDocIds))

        # è‡ªé€‚åº”æƒé‡è°ƒæ•´
        if alpha is None or beta is None:
            # å¦‚æœé‡å åº¦é«˜ï¼Œè¯´æ˜ä¸¤ç§æ–¹æ³•ä¸€è‡´ï¼Œå¯ä»¥å¹³å‡æƒé‡
            if overlapRatio > 0.5:
                alpha = 0.5
                beta = 0.5
            else:
                # é‡å åº¦ä½æ—¶ï¼Œæ ¹æ®å¹³å‡åˆ†æ•°åŠ¨æ€è°ƒæ•´æƒé‡
                avgBm25 = np.mean(bm25NormScores)
                avgVector = np.mean(vectorNormScores)
                total = avgBm25 + avgVector
                if total > 0:
                    alpha = avgBm25 / total
                    beta = avgVector / total
                else:
                    alpha = beta = 0.5

        # æ„å»º doc_id åˆ°å½’ä¸€åŒ–åˆ†æ•°çš„æ˜ å°„
        bm25ScoreMap = {
            r["doc_id"]: bm25NormScores[i] for i, r in enumerate(bm25Results)
        }
        vectorScoreMap = {
            r["doc_id"]: vectorNormScores[i] for i, r in enumerate(vectorResults)
        }

        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„ doc_id
        allDocIds = set(bm25ScoreMap.keys()) | set(vectorScoreMap.keys())

        # è®¡ç®—èåˆåˆ†æ•°
        fusedScores = {}
        for docId in allDocIds:
            bm25Score = bm25ScoreMap.get(docId, 0.0)
            vectorScore = vectorScoreMap.get(docId, 0.0)
            fusedScores[docId] = alpha * bm25Score + beta * vectorScore

        # æ’åºå¹¶æ„å»ºç»“æœ
        sortedDocIds = sorted(
            fusedScores.keys(), key=lambda x: fusedScores[x], reverse=True
        )

        # è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯
        docInfoMap = {r["doc_id"]: r for r in bm25Results}
        docInfoMap.update({r["doc_id"]: r for r in vectorResults})

        results = []
        for rank, docId in enumerate(sortedDocIds, 1):
            if rank > topK:
                break
            docInfo = docInfoMap[docId]
            results.append(
                {
                    "rank": rank,
                    "doc_id": docId,
                    "term": docInfo["term"],
                    "subject": docInfo.get("subject", ""),
                    "score": fusedScores[docId],
                    "bm25_score": bm25ScoreMap.get(docId, 0.0),
                    "vector_score": vectorScoreMap.get(docId, 0.0),
                    "source": docInfo.get("source", ""),
                    "page": docInfo.get("page", None),
                }
            )

        return results

    def search(
        self,
        query: str,
        topK: int = 10,
        strategy: str = "weighted",
        alpha: float | None = None,
        beta: float | None = None,
        normalization: str = "percentile",
        rrfK: int = 60,
        expandQuery: bool = True,
        recallFactor: int = 5,
    ) -> list[dict[str, Any]]:
        """
        æ”¹è¿›çš„æ··åˆæ£€ç´¢

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            topK: è¿”å›çš„ç»“æœæ•°é‡
            strategy: èåˆç­–ç•¥ï¼ˆweighted æˆ– rrfï¼‰
            alpha: BM25 æƒé‡
            beta: å‘é‡æ£€ç´¢æƒé‡
            normalization: å½’ä¸€åŒ–æ–¹æ³•
            rrfK: RRF å‚æ•°
            expandQuery: æ˜¯å¦è¿›è¡ŒæŸ¥è¯¢æ‰©å±•
            recallFactor: å¬å›å› å­ï¼ˆæ£€ç´¢ topK * recallFactor ç”¨äºèåˆï¼‰

        Returns:
            èåˆåçš„ç»“æœåˆ—è¡¨
        """
        # æ‰§è¡Œä¸¤ç§æ£€ç´¢ï¼ˆè·å–æ›´å¤šç»“æœç”¨äºèåˆï¼‰
        recallTopK = topK * recallFactor

        print("ğŸ” æ‰§è¡Œ BM25+ æ£€ç´¢...")
        bm25Results = self.bm25Retriever.search(
            query, recallTopK, expandQuery=expandQuery, returnAll=False
        )

        print("ğŸ” æ‰§è¡Œå‘é‡æ£€ç´¢...")
        vectorResults = self.vectorRetriever.search(query, recallTopK)

        # èåˆç»“æœ
        print(f"ğŸ”€ èåˆç»“æœï¼ˆç­–ç•¥ï¼š{strategy}ï¼‰...")
        if strategy == "weighted":
            fusedResults = self.fuseWeightedImproved(
                bm25Results, vectorResults, topK, alpha, beta, normalization
            )
        elif strategy == "rrf":
            fusedResults = self.fuseRRFImproved(bm25Results, vectorResults, topK, rrfK)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èåˆç­–ç•¥ï¼š{strategy}")

        return fusedResults

    def batchSearch(
        self,
        queries: list[str],
        topK: int = 10,
        strategy: str = "weighted",
        **kwargs,
    ) -> dict[str, list[dict[str, Any]]]:
        """æ‰¹é‡æ··åˆæ£€ç´¢"""
        results = {}
        for query in queries:
            results[query] = self.search(query, topK, strategy, **kwargs)
        return results


def loadQueriesFromFile(filepath: str) -> list[str]:
    """ä»æ–‡ä»¶åŠ è½½æŸ¥è¯¢"""
    queries = []
    with open(filepath, encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                queries.append(line)
    return queries


def saveResults(results: dict[str, list[dict[str, Any]]], outputFile: str) -> None:
    """ä¿å­˜æŸ¥è¯¢ç»“æœåˆ°æ–‡ä»¶"""
    dirname = os.path.dirname(outputFile)
    if dirname:
        os.makedirs(dirname, exist_ok=True)

    with open(outputFile, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜ï¼š{outputFile}")


def printResults(query: str, results: list[dict[str, Any]], strategy: str) -> None:
    """æ‰“å°æŸ¥è¯¢ç»“æœ"""
    print("\n" + "=" * 80)
    print(f"ğŸ” æŸ¥è¯¢ï¼š{query}")
    print(f"ğŸ”€ èåˆç­–ç•¥ï¼š{strategy}")
    print("=" * 80)

    if not results:
        print("âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
        return

    for result in results:
        print(f"\nğŸ† Rank {result['rank']}")
        print(f"  ğŸ“„ Doc ID: {result['doc_id']}")
        print(f"  ğŸ“š æœ¯è¯­ï¼š{result['term']}")
        print(f"  ğŸ“– å­¦ç§‘ï¼š{result['subject']}")
        print(f"  ğŸ“Š èåˆåˆ†æ•°ï¼š{result['score']:.4f}")

        if strategy == "weighted":
            print(f"     â”œâ”€ BM25: {result.get('bm25_score', 0):.4f}")
            print(f"     â””â”€ å‘é‡ï¼š{result.get('vector_score', 0):.4f}")
        elif strategy == "rrf":
            print(f"     â”œâ”€ BM25 Rank: {result.get('bm25_rank', 'N/A')}")
            print(f"     â””â”€ å‘é‡ Rank: {result.get('vector_rank', 'N/A')}")

        print(f"  ğŸ“— æ¥æºï¼š{result['source']}")
        if result.get("page"):
            print(f"  ğŸ“„ é¡µç ï¼š{result['page']}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ··åˆæ£€ç´¢ + æ”¹è¿›ç‰ˆ")
    parser.add_argument("--query", type=str, help="å•æ¬¡æŸ¥è¯¢å­—ç¬¦ä¸²")
    parser.add_argument("--query-file", type=str, help="æ‰¹é‡æŸ¥è¯¢æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--topk", type=int, default=10, help="è¿”å›çš„ç»“æœæ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰"
    )
    parser.add_argument("--output", type=str, help="è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--strategy",
        type=str,
        default="weighted",
        choices=["weighted", "rrf"],
        help="èåˆç­–ç•¥",
    )
    parser.add_argument("--alpha", type=float, help="BM25 æƒé‡")
    parser.add_argument("--beta", type=float, help="å‘é‡æ£€ç´¢æƒé‡")
    parser.add_argument(
        "--normalization",
        type=str,
        default="percentile",
        choices=["minmax", "zscore", "percentile"],
        help="å½’ä¸€åŒ–æ–¹æ³•",
    )
    parser.add_argument("--rrf-k", type=int, default=60, help="RRF å‚æ•° k")
    parser.add_argument("--corpus", type=str, help="è¯­æ–™æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--bm25-index", type=str, help="BM25 ç´¢å¼•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--vector-index", type=str, help="å‘é‡ç´¢å¼•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--vector-embedding", type=str, help="å‘é‡åµŒå…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--terms", type=str, help="æœ¯è¯­æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--model",
        type=str,
        default="paraphrase-multilingual-MiniLM-L12-v2",
        help="Sentence Transformer æ¨¡å‹åç§°",
    )
    parser.add_argument("--no-expand", action="store_true", help="ç¦ç”¨æŸ¥è¯¢æ‰©å±•")
    parser.add_argument(
        "--recall-factor",
        type=int,
        default=5,
        help="å¬å›å› å­ï¼ˆæ£€ç´¢ topK * factor ç”¨äºèåˆï¼‰",
    )
    parser.add_argument("--alpha", type=float, help="BM25 æƒé‡ï¼ˆé»˜è®¤ 0.7ï¼‰")
    parser.add_argument("--beta", type=float, help="å‘é‡æ£€ç´¢æƒé‡ï¼ˆé»˜è®¤ 0.3ï¼‰")

    args = parser.parse_args()

    # é»˜è®¤è·¯å¾„
    corpusFile = args.corpus or os.path.join(
        config.PROCESSED_DIR, "retrieval", "corpus.jsonl"
    )
    bm25IndexFile = args.bm25_index or os.path.join(
        config.PROCESSED_DIR, "retrieval", "bm25plus_index.pkl"
    )
    vectorIndexFile = args.vector_index or os.path.join(
        config.PROCESSED_DIR, "retrieval", "vector_index.faiss"
    )
    vectorEmbeddingFile = args.vector_embedding or os.path.join(
        config.PROCESSED_DIR, "retrieval", "vector_embeddings.npz"
    )
    termsFile = args.terms or os.path.join(
        config.PROCESSED_DIR, "terms", "all_terms.json"
    )

    print("=" * 80)
    print("ğŸ” æ··åˆæ£€ç´¢ + æ”¹è¿›ç‰ˆ")
    print("=" * 80)
    print(f"ğŸ“‚ è¯­æ–™æ–‡ä»¶ï¼š{corpusFile}")
    print(f"ğŸ“‚ BM25+ ç´¢å¼•ï¼š{bm25IndexFile}")
    print(f"ğŸ“‚ å‘é‡ç´¢å¼•ï¼š{vectorIndexFile}")
    print(f"ğŸ”€ èåˆç­–ç•¥ï¼š{args.strategy}")
    if args.strategy == "weighted":
        print(f"âš–ï¸  æƒé‡ï¼šBM25={args.alpha or 0.7}, å‘é‡={args.beta or 0.3}")
    print(f"ğŸ” æŸ¥è¯¢æ‰©å±•ï¼š{'ç¦ç”¨' if args.no_expand else 'å¯ç”¨'}")
    print(f"ğŸ“ˆ å¬å›å› å­ï¼š{args.recall_factor}")
    print()

    # åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
    retriever = HybridPlusRetriever(
        corpusFile,
        bm25IndexFile,
        vectorIndexFile,
        vectorEmbeddingFile,
        args.model,
        termsFile,
    )

    # æ‰§è¡ŒæŸ¥è¯¢
    if args.query:
        results = retriever.search(
            args.query,
            args.topk,
            args.strategy,
            args.alpha or (0.7 if args.strategy == "weighted" else None),
            args.beta or (0.3 if args.strategy == "weighted" else None),
            args.normalization,
            args.rrf_k,
            not args.no_expand,
            args.recall_factor,
        )
        printResults(args.query, results, args.strategy)

        if args.output:
            saveResults({args.query: results}, args.output)

    elif args.query_file:
        print(f"ğŸ“‚ åŠ è½½æŸ¥è¯¢ï¼š{args.query_file}")
        queries = loadQueriesFromFile(args.query_file)
        print(f"âœ… å·²åŠ è½½ {len(queries)} ä¸ªæŸ¥è¯¢\n")

        results = retriever.batchSearch(
            queries,
            args.topk,
            args.strategy,
            alpha=args.alpha or (0.7 if args.strategy == "weighted" else None),
            beta=args.beta or (0.3 if args.strategy == "weighted" else None),
            normalization=args.normalization,
            rrfK=args.rrf_k,
            expandQuery=not args.no_expand,
            recallFactor=args.recall_factor,
        )

        for query, queryResults in results.items():
            printResults(query, queryResults, args.strategy)

        if args.output:
            saveResults(results, args.output)
        else:
            defaultOutput = os.path.join(
                config.PROJECT_ROOT, "outputs", "hybrid_plus_results.json"
            )
            saveResults(results, defaultOutput)

    else:
        print("âš ï¸  è¯·æä¾›æŸ¥è¯¢å‚æ•°")
        parser.print_help()


if __name__ == "__main__":
    main()
