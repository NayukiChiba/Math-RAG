"""
æ··åˆæ£€ç´¢

åŠŸèƒ½ï¼š
1. ç»“åˆ BM25 å’Œå‘é‡æ£€ç´¢çš„ä¼˜åŠ¿
2. æ”¯æŒå¤šç§å½’ä¸€åŒ–ç­–ç•¥ï¼ˆmin-maxã€z-scoreï¼‰
3. æ”¯æŒå¤šç§èåˆç­–ç•¥ï¼ˆåŠ æƒèåˆã€RRFï¼‰
4. å¯é…ç½®æƒé‡å‚æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
    # åŠ æƒèåˆï¼ˆé»˜è®¤ï¼‰
    python retrieval/retrievalHybrid.py --query "æ³°å‹’å±•å¼€" --topk 10

    # æŒ‡å®šæƒé‡
    python retrieval/retrievalHybrid.py --query "æ³°å‹’å±•å¼€" --alpha 0.7 --beta 0.3

    # ä½¿ç”¨ RRF èåˆ
    python retrieval/retrievalHybrid.py --query "æ³°å‹’å±•å¼€" --strategy rrf

    # æ‰¹é‡æŸ¥è¯¢
    python retrieval/retrievalHybrid.py --query-file queries.txt --output results.json
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Any

import numpy as np

# è·¯å¾„è°ƒæ•´
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

import config
from retrieval.retrievalBM25 import BM25Retriever
from retrieval.retrievalVector import VectorRetriever


class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨"""

    def __init__(
        self,
        corpusFile: str,
        bm25IndexFile: str,
        vectorIndexFile: str,
        vectorEmbeddingFile: str,
        modelName: str = "paraphrase-multilingual-MiniLM-L12-v2",
    ):
        """
        åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨

        Args:
            corpusFile: è¯­æ–™æ–‡ä»¶è·¯å¾„
            bm25IndexFile: BM25 ç´¢å¼•æ–‡ä»¶è·¯å¾„
            vectorIndexFile: å‘é‡ç´¢å¼•æ–‡ä»¶è·¯å¾„
            vectorEmbeddingFile: å‘é‡åµŒå…¥æ–‡ä»¶è·¯å¾„
            modelName: Sentence Transformer æ¨¡å‹åç§°
        """
        self.corpusFile = corpusFile

        # åˆå§‹åŒ– BM25 æ£€ç´¢å™¨
        print("ğŸ”§ åˆå§‹åŒ– BM25 æ£€ç´¢å™¨...")
        self.bm25Retriever = BM25Retriever(corpusFile, bm25IndexFile)
        if not self.bm25Retriever.loadIndex():
            print("âš ï¸  BM25 ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
            self.bm25Retriever.buildIndex()
            self.bm25Retriever.saveIndex()

        # åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨
        print("ğŸ”§ åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨...")
        self.vectorRetriever = VectorRetriever(
            corpusFile, modelName, vectorIndexFile, vectorEmbeddingFile
        )
        if not self.vectorRetriever.loadIndex():
            print("âš ï¸  å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼Œæ­£åœ¨æ„å»º...")
            self.vectorRetriever.buildIndex()
            self.vectorRetriever.saveIndex()

        print("âœ… æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ\n")

    def normalizeMinMax(self, scores: list[float]) -> list[float]:
        """
        Min-Max å½’ä¸€åŒ–

        Args:
            scores: åŸå§‹åˆ†æ•°åˆ—è¡¨

        Returns:
            å½’ä¸€åŒ–åçš„åˆ†æ•°åˆ—è¡¨
        """
        if not scores:
            return []

        minScore = min(scores)
        maxScore = max(scores)

        if maxScore == minScore:
            return [1.0] * len(scores)

        return [(s - minScore) / (maxScore - minScore) for s in scores]

    def normalizeZScore(self, scores: list[float]) -> list[float]:
        """
        Z-Score å½’ä¸€åŒ–

        Args:
            scores: åŸå§‹åˆ†æ•°åˆ—è¡¨

        Returns:
            å½’ä¸€åŒ–åçš„åˆ†æ•°åˆ—è¡¨
        """
        if not scores:
            return []

        mean = np.mean(scores)
        std = np.std(scores)

        if std == 0:
            return [0.0] * len(scores)

        return [(s - mean) / std for s in scores]

    def fuseWeighted(
        self,
        bm25Results: list[dict[str, Any]],
        vectorResults: list[dict[str, Any]],
        alpha: float = 0.5,
        beta: float = 0.5,
        normalization: str = "minmax",
    ) -> list[dict[str, Any]]:
        """
        åŠ æƒèåˆç­–ç•¥

        Args:
            bm25Results: BM25 æ£€ç´¢ç»“æœ
            vectorResults: å‘é‡æ£€ç´¢ç»“æœ
            alpha: BM25 æƒé‡
            beta: å‘é‡æ£€ç´¢æƒé‡
            normalization: å½’ä¸€åŒ–æ–¹æ³•ï¼ˆminmax æˆ– zscoreï¼‰

        Returns:
            èåˆåçš„ç»“æœåˆ—è¡¨
        """
        # æå–åˆ†æ•°
        bm25Scores = [r["score"] for r in bm25Results]
        vectorScores = [r["score"] for r in vectorResults]

        # å½’ä¸€åŒ–
        if normalization == "minmax":
            bm25NormScores = self.normalizeMinMax(bm25Scores)
            vectorNormScores = self.normalizeMinMax(vectorScores)
        elif normalization == "zscore":
            bm25NormScores = self.normalizeZScore(bm25Scores)
            vectorNormScores = self.normalizeZScore(vectorScores)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å½’ä¸€åŒ–æ–¹æ³•: {normalization}")

        # æ„å»º doc_id åˆ°å½’ä¸€åŒ–åˆ†æ•°çš„æ˜ å°„
        bm25ScoreMap = {
            r["doc_id"]: bm25NormScores[i] for i, r in enumerate(bm25Results)
        }
        vectorScoreMap = {
            r["doc_id"]: vectorNormScores[i] for i, r in enumerate(vectorResults)
        }

        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„ doc_id
        allDocIds = set(bm25ScoreMap.keys()) | set(vectorScoreMap.keys())

        # è®¡ç®—èåˆåˆ†æ•°
        fusedScores = {}
        for docId in allDocIds:
            bm25Score = bm25ScoreMap.get(docId, 0.0)
            vectorScore = vectorScoreMap.get(docId, 0.0)
            fusedScores[docId] = alpha * bm25Score + beta * vectorScore

        # æ’åºå¹¶æ„å»ºç»“æœ
        sortedDocIds = sorted(
            fusedScores.keys(), key=lambda x: fusedScores[x], reverse=True
        )

        # è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯ï¼ˆä¼˜å…ˆä» BM25 ç»“æœä¸­è·å–ï¼Œå› ä¸ºåŒ…å«æ›´å¤šå­—æ®µï¼‰
        docInfoMap = {r["doc_id"]: r for r in bm25Results}
        docInfoMap.update({r["doc_id"]: r for r in vectorResults})

        results = []
        for rank, docId in enumerate(sortedDocIds, 1):
            docInfo = docInfoMap[docId]
            results.append(
                {
                    "rank": rank,
                    "doc_id": docId,
                    "term": docInfo["term"],
                    "subject": docInfo.get("subject", ""),
                    "score": fusedScores[docId],
                    "bm25_score": bm25ScoreMap.get(docId, 0.0),
                    "vector_score": vectorScoreMap.get(docId, 0.0),
                    "source": docInfo.get("source", ""),
                    "page": docInfo.get("page", None),
                }
            )

        return results

    def fuseRRF(
        self,
        bm25Results: list[dict[str, Any]],
        vectorResults: list[dict[str, Any]],
        k: int = 60,
    ) -> list[dict[str, Any]]:
        """
        Reciprocal Rank Fusion (RRF) èåˆç­–ç•¥

        Args:
            bm25Results: BM25 æ£€ç´¢ç»“æœ
            vectorResults: å‘é‡æ£€ç´¢ç»“æœ
            k: RRF å‚æ•°ï¼ˆé»˜è®¤ 60ï¼‰

        Returns:
            èåˆåçš„ç»“æœåˆ—è¡¨
        """
        # æ„å»º doc_id åˆ°æ’åçš„æ˜ å°„
        bm25RankMap = {r["doc_id"]: r["rank"] for r in bm25Results}
        vectorRankMap = {r["doc_id"]: r["rank"] for r in vectorResults}

        # æ”¶é›†æ‰€æœ‰å”¯ä¸€çš„ doc_id
        allDocIds = set(bm25RankMap.keys()) | set(vectorRankMap.keys())

        # è®¡ç®— RRF åˆ†æ•°ï¼ˆæ ‡å‡† RRFï¼šä»…å¯¹æœ‰æ’åçš„ç»“æœæ±‚å’Œï¼Œæœªå‘½ä¸­æ—¶è´¡çŒ®ä¸º 0ï¼‰
        rrfScores = {}
        for docId in allDocIds:
            rrfScore = 0.0
            # BM25 è´¡çŒ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if docId in bm25RankMap:
                rrfScore += 1.0 / (k + bm25RankMap[docId])
            # å‘é‡æ£€ç´¢è´¡çŒ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if docId in vectorRankMap:
                rrfScore += 1.0 / (k + vectorRankMap[docId])
            rrfScores[docId] = rrfScore

        # æ’åºå¹¶æ„å»ºç»“æœ
        sortedDocIds = sorted(
            rrfScores.keys(), key=lambda x: rrfScores[x], reverse=True
        )

        # è·å–æ–‡æ¡£è¯¦ç»†ä¿¡æ¯
        docInfoMap = {r["doc_id"]: r for r in bm25Results}
        docInfoMap.update({r["doc_id"]: r for r in vectorResults})

        results = []
        for rank, docId in enumerate(sortedDocIds, 1):
            docInfo = docInfoMap[docId]
            results.append(
                {
                    "rank": rank,
                    "doc_id": docId,
                    "term": docInfo["term"],
                    "subject": docInfo.get("subject", ""),
                    "score": rrfScores[docId],
                    "bm25_rank": bm25RankMap.get(docId, None),
                    "vector_rank": vectorRankMap.get(docId, None),
                    "source": docInfo.get("source", ""),
                    "page": docInfo.get("page", None),
                }
            )

        return results

    def search(
        self,
        query: str,
        topK: int = 10,
        strategy: str = "weighted",
        alpha: float = 0.5,
        beta: float = 0.5,
        normalization: str = "minmax",
        rrfK: int = 60,
    ) -> list[dict[str, Any]]:
        """
        æ··åˆæ£€ç´¢

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            topK: è¿”å›çš„ç»“æœæ•°é‡
            strategy: èåˆç­–ç•¥ï¼ˆweighted æˆ– rrfï¼‰
            alpha: BM25 æƒé‡ï¼ˆä»… weighted ç­–ç•¥ï¼‰
            beta: å‘é‡æ£€ç´¢æƒé‡ï¼ˆä»… weighted ç­–ç•¥ï¼‰
            normalization: å½’ä¸€åŒ–æ–¹æ³•ï¼ˆminmax æˆ– zscoreï¼Œä»… weighted ç­–ç•¥ï¼‰
            rrfK: RRF å‚æ•°ï¼ˆä»… rrf ç­–ç•¥ï¼‰

        Returns:
            èåˆåçš„ç»“æœåˆ—è¡¨
        """
        # æ‰§è¡Œä¸¤ç§æ£€ç´¢
        print("ğŸ” æ‰§è¡Œ BM25 æ£€ç´¢...")
        bm25Results = self.bm25Retriever.search(query, topK * 2)  # è·å–æ›´å¤šç»“æœç”¨äºèåˆ

        print("ğŸ” æ‰§è¡Œå‘é‡æ£€ç´¢...")
        vectorResults = self.vectorRetriever.search(query, topK * 2)

        # èåˆç»“æœ
        print(f"ğŸ”€ èåˆç»“æœï¼ˆç­–ç•¥: {strategy}ï¼‰...")
        if strategy == "weighted":
            fusedResults = self.fuseWeighted(
                bm25Results, vectorResults, alpha, beta, normalization
            )
        elif strategy == "rrf":
            fusedResults = self.fuseRRF(bm25Results, vectorResults, rrfK)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èåˆç­–ç•¥: {strategy}")

        # è¿”å› TopK
        return fusedResults[:topK]

    def batchSearch(
        self,
        queries: list[str],
        topK: int = 10,
        strategy: str = "weighted",
        alpha: float = 0.5,
        beta: float = 0.5,
        normalization: str = "minmax",
        rrfK: int = 60,
    ) -> dict[str, list[dict[str, Any]]]:
        """
        æ‰¹é‡æ··åˆæ£€ç´¢

        Args:
            queries: æŸ¥è¯¢å­—ç¬¦ä¸²åˆ—è¡¨
            topK: æ¯ä¸ªæŸ¥è¯¢è¿”å›çš„ç»“æœæ•°é‡
            strategy: èåˆç­–ç•¥
            alpha: BM25 æƒé‡
            beta: å‘é‡æ£€ç´¢æƒé‡
            normalization: å½’ä¸€åŒ–æ–¹æ³•
            rrfK: RRF å‚æ•°

        Returns:
            å­—å…¸ï¼Œé”®ä¸ºæŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œå€¼ä¸ºç»“æœåˆ—è¡¨
        """
        results = {}
        for query in queries:
            results[query] = self.search(
                query, topK, strategy, alpha, beta, normalization, rrfK
            )
        return results


def loadQueriesFromFile(filepath: str) -> list[str]:
    """
    ä»æ–‡ä»¶åŠ è½½æŸ¥è¯¢

    Args:
        filepath: æŸ¥è¯¢æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªæŸ¥è¯¢ï¼‰

    Returns:
        æŸ¥è¯¢åˆ—è¡¨
    """
    queries = []
    with open(filepath, encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                queries.append(line)
    return queries


def saveResults(results: dict[str, list[dict[str, Any]]], outputFile: str) -> None:
    """
    ä¿å­˜æŸ¥è¯¢ç»“æœåˆ°æ–‡ä»¶

    Args:
        results: æŸ¥è¯¢ç»“æœå­—å…¸
        outputFile: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    dirname = os.path.dirname(outputFile)
    if dirname:
        os.makedirs(dirname, exist_ok=True)

    with open(outputFile, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {outputFile}")


def printResults(query: str, results: list[dict[str, Any]], strategy: str) -> None:
    """
    æ‰“å°æŸ¥è¯¢ç»“æœ

    Args:
        query: æŸ¥è¯¢å­—ç¬¦ä¸²
        results: ç»“æœåˆ—è¡¨
        strategy: èåˆç­–ç•¥
    """
    print("\n" + "=" * 80)
    print(f"ğŸ” æŸ¥è¯¢: {query}")
    print(f"ğŸ”€ èåˆç­–ç•¥: {strategy}")
    print("=" * 80)

    if not results:
        print("âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
        return

    for result in results:
        print(f"\nğŸ† Rank {result['rank']}")
        print(f"  ğŸ“„ Doc ID: {result['doc_id']}")
        print(f"  ğŸ“š æœ¯è¯­: {result['term']}")
        print(f"  ğŸ“– å­¦ç§‘: {result['subject']}")
        print(f"  ğŸ“Š èåˆåˆ†æ•°: {result['score']:.4f}")

        if strategy == "weighted":
            print(f"     â”œâ”€ BM25: {result.get('bm25_score', 0):.4f}")
            print(f"     â””â”€ å‘é‡: {result.get('vector_score', 0):.4f}")
        elif strategy == "rrf":
            print(f"     â”œâ”€ BM25 Rank: {result.get('bm25_rank', 'N/A')}")
            print(f"     â””â”€ å‘é‡ Rank: {result.get('vector_rank', 'N/A')}")

        print(f"  ğŸ“— æ¥æº: {result['source']}")
        if result.get("page"):
            print(f"  ğŸ“„ é¡µç : {result['page']}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ··åˆæ£€ç´¢")
    parser.add_argument("--query", type=str, help="å•æ¬¡æŸ¥è¯¢å­—ç¬¦ä¸²")
    parser.add_argument("--query-file", type=str, help="æ‰¹é‡æŸ¥è¯¢æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--topk", type=int, default=10, help="è¿”å›çš„ç»“æœæ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰"
    )
    parser.add_argument("--output", type=str, help="è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆJSON æ ¼å¼ï¼‰")
    parser.add_argument(
        "--strategy",
        type=str,
        default="weighted",
        choices=["weighted", "rrf"],
        help="èåˆç­–ç•¥ï¼ˆweighted æˆ– rrfï¼Œé»˜è®¤ weightedï¼‰",
    )
    parser.add_argument(
        "--alpha", type=float, default=0.5, help="BM25 æƒé‡ï¼ˆé»˜è®¤ 0.5ï¼‰"
    )
    parser.add_argument(
        "--beta", type=float, default=0.5, help="å‘é‡æ£€ç´¢æƒé‡ï¼ˆé»˜è®¤ 0.5ï¼‰"
    )
    parser.add_argument(
        "--normalization",
        type=str,
        default="minmax",
        choices=["minmax", "zscore"],
        help="å½’ä¸€åŒ–æ–¹æ³•ï¼ˆminmax æˆ– zscoreï¼Œé»˜è®¤ minmaxï¼‰",
    )
    parser.add_argument("--rrf-k", type=int, default=60, help="RRF å‚æ•° kï¼ˆé»˜è®¤ 60ï¼‰")
    parser.add_argument("--corpus", type=str, help="è¯­æ–™æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--bm25-index", type=str, help="BM25 ç´¢å¼•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--vector-index", type=str, help="å‘é‡ç´¢å¼•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--vector-embedding", type=str, help="å‘é‡åµŒå…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--model",
        type=str,
        default="paraphrase-multilingual-MiniLM-L12-v2",
        help="Sentence Transformer æ¨¡å‹åç§°",
    )

    args = parser.parse_args()

    # é»˜è®¤è·¯å¾„
    corpusFile = args.corpus or os.path.join(
        config.PROCESSED_DIR, "retrieval", "corpus.jsonl"
    )
    bm25IndexFile = args.bm25_index or os.path.join(
        config.PROCESSED_DIR, "retrieval", "bm25_index.pkl"
    )
    vectorIndexFile = args.vector_index or os.path.join(
        config.PROCESSED_DIR, "retrieval", "vector_index.faiss"
    )
    vectorEmbeddingFile = args.vector_embedding or os.path.join(
        config.PROCESSED_DIR, "retrieval", "vector_embeddings.npz"
    )

    print("=" * 80)
    print("ğŸ” æ··åˆæ£€ç´¢")
    print("=" * 80)
    print(f"ğŸ“‚ è¯­æ–™æ–‡ä»¶: {corpusFile}")
    print(f"ğŸ“‚ BM25 ç´¢å¼•: {bm25IndexFile}")
    print(f"ğŸ“‚ å‘é‡ç´¢å¼•: {vectorIndexFile}")
    print(f"ğŸ“‚ å‘é‡åµŒå…¥: {vectorEmbeddingFile}")
    print(f"ğŸ¤– æ¨¡å‹: {args.model}")
    print(f"ğŸ”€ èåˆç­–ç•¥: {args.strategy}")
    if args.strategy == "weighted":
        print(f"âš–ï¸  æƒé‡: BM25={args.alpha}, å‘é‡={args.beta}")
        print(f"ğŸ“ å½’ä¸€åŒ–: {args.normalization}")
    elif args.strategy == "rrf":
        print(f"ğŸ”¢ RRF k: {args.rrf_k}")
    print()

    # åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
    retriever = HybridRetriever(
        corpusFile,
        bm25IndexFile,
        vectorIndexFile,
        vectorEmbeddingFile,
        args.model,
    )

    # æ‰§è¡ŒæŸ¥è¯¢
    if args.query:
        # å•æ¬¡æŸ¥è¯¢
        results = retriever.search(
            args.query,
            args.topk,
            args.strategy,
            args.alpha,
            args.beta,
            args.normalization,
            args.rrf_k,
        )
        printResults(args.query, results, args.strategy)

        if args.output:
            saveResults({args.query: results}, args.output)

    elif args.query_file:
        # æ‰¹é‡æŸ¥è¯¢
        print(f"ğŸ“‚ åŠ è½½æŸ¥è¯¢: {args.query_file}")
        queries = loadQueriesFromFile(args.query_file)
        print(f"âœ… å·²åŠ è½½ {len(queries)} ä¸ªæŸ¥è¯¢\n")

        results = retriever.batchSearch(
            queries,
            args.topk,
            args.strategy,
            args.alpha,
            args.beta,
            args.normalization,
            args.rrf_k,
        )

        # æ‰“å°æ¯ä¸ªæŸ¥è¯¢çš„ç»“æœ
        for query, queryResults in results.items():
            printResults(query, queryResults, args.strategy)

        # ä¿å­˜ç»“æœ
        if args.output:
            saveResults(results, args.output)
        else:
            # é»˜è®¤è¾“å‡ºæ–‡ä»¶
            defaultOutput = os.path.join(
                config.PROJECT_ROOT, "outputs", "hybrid_results.json"
            )
            saveResults(results, defaultOutput)

    else:
        print("âš ï¸  è¯·æä¾›æŸ¥è¯¢å‚æ•°ï¼š")
        print("  --query 'your query'  # å•æ¬¡æŸ¥è¯¢")
        print("  --query-file queries.txt  # æ‰¹é‡æŸ¥è¯¢")
        parser.print_help()


if __name__ == "__main__":
    main()
