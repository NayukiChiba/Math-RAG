"""
å¸¦é‡æ’åºçš„æ£€ç´¢

åŠŸèƒ½ï¼š
1. ä½¿ç”¨ Cross-Encoder è¿›è¡Œé‡æ’åº
2. å…ˆå¬å›å¤§é‡å€™é€‰ï¼Œå†ç”¨æ›´ç²¾ç»†çš„æ¨¡å‹é‡æ’
3. æ”¯æŒå¤šç§é‡æ’åºç­–ç•¥
4. å¯é€‰çš„é‡æ’åºæ¨¡å‹

ä½¿ç”¨æ–¹æ³•ï¼š
    # å•æ¬¡æŸ¥è¯¢ï¼ˆä½¿ç”¨é»˜è®¤é‡æ’åºï¼‰
    python retrieval/retrievalWithReranker.py --query "æ³°å‹’å±•å¼€" --topk 10

    # æŒ‡å®šé‡æ’åºæ¨¡å‹
    python retrieval/retrievalWithReranker.py --query "æ³°å‹’å±•å¼€" --topk 10 --reranker-model bge-reranker-base

    # è°ƒæ•´å¬å›æ•°é‡
    python retrieval/retrievalWithReranker.py --query "æ³°å‹’å±•å¼€" --topk 10 --recall-topk 50
"""

import argparse
import json
import os
import sys
from pathlib import Path
from typing import Any

# è·¯å¾„è°ƒæ•´
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

import config


class RerankerRetriever:
    """å¸¦é‡æ’åºçš„æ£€ç´¢å™¨"""

    def __init__(
        self,
        corpusFile: str,
        bm25IndexFile: str,
        vectorIndexFile: str,
        vectorEmbeddingFile: str,
        modelName: str = "paraphrase-multilingual-MiniLM-L12-v2",
        rerankerModel: str = "bge-reranker-base",
    ):
        """
        åˆå§‹åŒ–å¸¦é‡æ’åºçš„æ£€ç´¢å™¨

        Args:
            corpusFile: è¯­æ–™æ–‡ä»¶è·¯å¾„
            bm25IndexFile: BM25 ç´¢å¼•æ–‡ä»¶è·¯å¾„
            vectorIndexFile: å‘é‡ç´¢å¼•æ–‡ä»¶è·¯å¾„
            vectorEmbeddingFile: å‘é‡åµŒå…¥æ–‡ä»¶è·¯å¾„
            modelName: Sentence Transformer æ¨¡å‹åç§°
            rerankerModel: é‡æ’åºæ¨¡å‹åç§°
        """
        self.corpusFile = corpusFile
        self.rerankerModelName = rerankerModel
        self.corpus = []
        self.reranker = None
        self.bm25 = None
        self.vectorIndex = None
        self.vectorModel = None

        # åŠ è½½ BM25 ç´¢å¼•
        self._loadBM25Index(bm25IndexFile)

        # åŠ è½½å‘é‡ç´¢å¼•
        self._loadVectorIndex(vectorIndexFile, vectorEmbeddingFile, modelName)

        # åŠ è½½é‡æ’åºæ¨¡å‹
        self._loadReranker()

    def _loadBM25Index(self, indexFile: str) -> None:
        """åŠ è½½ BM25 ç´¢å¼•"""
        print("ğŸ“‚ åŠ è½½ BM25 ç´¢å¼•...")

        if not os.path.exists(indexFile):
            raise FileNotFoundError(f"BM25 ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼š{indexFile}")

        import pickle

        with open(indexFile, "rb") as f:
            indexData = pickle.load(f)

        self.bm25 = indexData["bm25"]
        self.corpus = indexData["corpus"]
        print(f"âœ… å·²åŠ è½½ BM25 ç´¢å¼•ï¼ˆ{len(self.corpus)} æ¡æ–‡æ¡£ï¼‰")

    def _loadVectorIndex(
        self, indexFile: str, embeddingFile: str, modelName: str
    ) -> None:
        """åŠ è½½å‘é‡ç´¢å¼•"""
        print("ğŸ“‚ åŠ è½½å‘é‡ç´¢å¼•...")

        try:
            import faiss
            from sentence_transformers import SentenceTransformer
        except ImportError:
            print("âŒ ç¼ºå°‘ä¾èµ–åº“")
            sys.exit(1)

        # åŠ è½½å‘é‡æ¨¡å‹
        print(f"ğŸ¤– åŠ è½½å‘é‡æ¨¡å‹ï¼š{modelName}")
        self.vectorModel = SentenceTransformer(modelName)

        # åŠ è½½ FAISS ç´¢å¼•
        if os.path.exists(indexFile):
            self.vectorIndex = faiss.read_index(indexFile)
            print("âœ… å·²åŠ è½½ FAISS ç´¢å¼•")
        else:
            print(f"âš ï¸  å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼š{indexFile}")
            self.vectorIndex = None

    def _loadReranker(self) -> None:
        """åŠ è½½é‡æ’åºæ¨¡å‹"""
        print(f"ğŸ¤– åŠ è½½é‡æ’åºæ¨¡å‹ï¼š{self.rerankerModelName}")

        try:
            from sentence_transformers import CrossEncoder

            self.reranker = CrossEncoder(self.rerankerModelName)
            print("âœ… é‡æ’åºæ¨¡å‹åŠ è½½å®Œæˆ")
        except ImportError:
            print("âš ï¸  æœªå®‰è£… CrossEncoderï¼Œé‡æ’åºåŠŸèƒ½å°†ä¸å¯ç”¨")
            print("è¯·å®‰è£…ï¼špip install sentence-transformers")
            self.reranker = None
        except Exception as e:
            print(f"âš ï¸  é‡æ’åºæ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}")
            self.reranker = None

    def _retrieveCandidates(self, query: str, topK: int = 50) -> list[dict[str, Any]]:
        """
        æ£€ç´¢å€™é€‰æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            topK: å€™é€‰æ•°é‡

        Returns:
            å€™é€‰æ–‡æ¡£åˆ—è¡¨
        """
        candidates = {}

        # BM25 æ£€ç´¢
        if self.bm25 is not None:
            # ç®€å•åˆ†è¯
            tokens = query.split()
            scores = self.bm25.get_scores(tokens)

            # è·å– topK å€™é€‰
            topIndices = sorted(
                range(len(scores)), key=lambda i: scores[i], reverse=True
            )[: topK // 2]

            for idx in topIndices:
                if scores[idx] > 0:
                    doc = self.corpus[idx]
                    candidates[idx] = {
                        "doc_idx": idx,
                        "doc_id": doc["doc_id"],
                        "term": doc["term"],
                        "subject": doc.get("subject", ""),
                        "text": doc["text"],
                        "bm25_score": float(scores[idx]),
                        "source": doc.get("source", ""),
                        "page": doc.get("page", None),
                    }

        # å‘é‡æ£€ç´¢
        if self.vectorIndex is not None and self.vectorModel is not None:
            import faiss

            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            queryEmbedding = self.vectorModel.encode([query], convert_to_numpy=True)
            faiss.normalize_L2(queryEmbedding)

            # æ£€ç´¢
            scores, indices = self.vectorIndex.search(queryEmbedding, topK // 2)

            for score, idx in zip(scores[0], indices[0]):
                if idx == -1:
                    continue
                doc = self.corpus[idx]
                if idx not in candidates:
                    candidates[idx] = {
                        "doc_idx": idx,
                        "doc_id": doc["doc_id"],
                        "term": doc["term"],
                        "subject": doc.get("subject", ""),
                        "text": doc["text"],
                        "vector_score": float(score),
                        "source": doc.get("source", ""),
                        "page": doc.get("page", None),
                    }
                else:
                    # æ›´æ–°å‘é‡åˆ†æ•°
                    candidates[idx]["vector_score"] = float(score)

        return list(candidates.values())

    def rerank(
        self,
        query: str,
        candidates: list[dict[str, Any]],
        topK: int = 10,
        useReranker: bool = True,
    ) -> list[dict[str, Any]]:
        """
        é‡æ’åºå€™é€‰æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            candidates: å€™é€‰æ–‡æ¡£åˆ—è¡¨
            topK: è¿”å›çš„ç»“æœæ•°é‡
            useReranker: æ˜¯å¦ä½¿ç”¨ Cross-Encoder é‡æ’åº

        Returns:
            é‡æ’åºåçš„ç»“æœåˆ—è¡¨
        """
        if not candidates:
            return []

        if useReranker and self.reranker is not None:
            # ä½¿ç”¨ Cross-Encoder é‡æ’åº
            print(f"ğŸ”„ ä½¿ç”¨é‡æ’åºæ¨¡å‹å¯¹ {len(candidates)} ä¸ªå€™é€‰è¿›è¡Œé‡æ’åº...")

            # æ„å»ºå¥å­å¯¹
            pairs = [[query, c["text"]] for c in candidates]

            # é¢„æµ‹åˆ†æ•°
            rerankScores = self.reranker.predict(pairs)

            # æ·»åŠ é‡æ’åºåˆ†æ•°
            for i, candidate in enumerate(candidates):
                candidate["reranker_score"] = float(rerankScores[i])

            # æŒ‰é‡æ’åºåˆ†æ•°æ’åº
            sortedCandidates = sorted(
                candidates, key=lambda x: x["reranker_score"], reverse=True
            )

        else:
            # ä¸ä½¿ç”¨é‡æ’åºï¼ŒæŒ‰ç»¼åˆåˆ†æ•°æ’åº
            print("ğŸ“Š æŒ‰ç»¼åˆåˆ†æ•°æ’åº...")

            for candidate in candidates:
                bm25Score = candidate.get("bm25_score", 0)
                vectorScore = candidate.get("vector_score", 0)
                # ç®€å•å¹³å‡
                candidate["combined_score"] = 0.5 * bm25Score + 0.5 * vectorScore

            sortedCandidates = sorted(
                candidates, key=lambda x: x["combined_score"], reverse=True
            )

        # è¿”å› topK
        results = []
        for rank, candidate in enumerate(sortedCandidates[:topK], 1):
            results.append(
                {
                    "rank": rank,
                    "doc_id": candidate["doc_id"],
                    "term": candidate["term"],
                    "subject": candidate["subject"],
                    "score": candidate.get(
                        "reranker_score", candidate.get("combined_score", 0)
                    ),
                    "source": candidate["source"],
                    "page": candidate.get("page"),
                    "bm25_score": candidate.get("bm25_score", 0),
                    "vector_score": candidate.get("vector_score", 0),
                }
            )

        return results

    def search(
        self,
        query: str,
        topK: int = 10,
        recallTopK: int = 50,
        useReranker: bool = True,
    ) -> list[dict[str, Any]]:
        """
        å¸¦é‡æ’åºçš„æ£€ç´¢

        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            topK: è¿”å›çš„ç»“æœæ•°é‡
            recallTopK: å¬å›å€™é€‰æ•°é‡
            useReranker: æ˜¯å¦ä½¿ç”¨é‡æ’åº

        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        # æ£€ç´¢å€™é€‰
        print(f"ğŸ“¥ å¬å›å€™é€‰æ–‡æ¡£ï¼ˆtop{recallTopK}ï¼‰...")
        candidates = self._retrieveCandidates(query, recallTopK)

        print(f"âœ… å¬å› {len(candidates)} ä¸ªå€™é€‰æ–‡æ¡£")

        # é‡æ’åº
        results = self.rerank(query, candidates, topK, useReranker)

        return results

    def batchSearch(
        self,
        queries: list[str],
        topK: int = 10,
        recallTopK: int = 50,
        useReranker: bool = True,
    ) -> dict[str, list[dict[str, Any]]]:
        """æ‰¹é‡æ£€ç´¢"""
        results = {}
        for query in queries:
            results[query] = self.search(query, topK, recallTopK, useReranker)
        return results


def loadQueriesFromFile(filepath: str) -> list[str]:
    """ä»æ–‡ä»¶åŠ è½½æŸ¥è¯¢"""
    queries = []
    with open(filepath, encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                queries.append(line)
    return queries


def saveResults(results: dict[str, list[dict[str, Any]]], outputFile: str) -> None:
    """ä¿å­˜æŸ¥è¯¢ç»“æœåˆ°æ–‡ä»¶"""
    dirname = os.path.dirname(outputFile)
    if dirname:
        os.makedirs(dirname, exist_ok=True)

    with open(outputFile, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜ï¼š{outputFile}")


def printResults(query: str, results: list[dict[str, Any]]) -> None:
    """æ‰“å°æŸ¥è¯¢ç»“æœ"""
    print("\n" + "=" * 80)
    print(f"ğŸ” æŸ¥è¯¢ï¼š{query}")
    print("=" * 80)

    if not results:
        print("âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
        return

    for result in results:
        print(f"\nğŸ† Rank {result['rank']}")
        print(f"  ğŸ“„ Doc ID: {result['doc_id']}")
        print(f"  ğŸ“š æœ¯è¯­ï¼š{result['term']}")
        print(f"  ğŸ“– å­¦ç§‘ï¼š{result['subject']}")
        print(f"  ğŸ“Š é‡æ’åºåˆ†æ•°ï¼š{result['score']:.4f}")
        print(f"     â”œâ”€ BM25: {result.get('bm25_score', 0):.4f}")
        print(f"     â””â”€ å‘é‡ï¼š{result.get('vector_score', 0):.4f}")
        print(f"  ğŸ“— æ¥æºï¼š{result['source']}")
        if result.get("page"):
            print(f"  ğŸ“„ é¡µç ï¼š{result['page']}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¸¦é‡æ’åºçš„æ£€ç´¢")
    parser.add_argument("--query", type=str, help="å•æ¬¡æŸ¥è¯¢å­—ç¬¦ä¸²")
    parser.add_argument("--query-file", type=str, help="æ‰¹é‡æŸ¥è¯¢æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--topk", type=int, default=10, help="è¿”å›çš„ç»“æœæ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰"
    )
    parser.add_argument(
        "--recall-topk", type=int, default=50, help="å¬å›å€™é€‰æ•°é‡ï¼ˆé»˜è®¤ 50ï¼‰"
    )
    parser.add_argument("--output", type=str, help="è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--corpus", type=str, help="è¯­æ–™æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--bm25-index", type=str, help="BM25 ç´¢å¼•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--vector-index", type=str, help="å‘é‡ç´¢å¼•æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--vector-embedding", type=str, help="å‘é‡åµŒå…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument(
        "--model",
        type=str,
        default="paraphrase-multilingual-MiniLM-L12-v2",
        help="Sentence Transformer æ¨¡å‹åç§°",
    )
    parser.add_argument(
        "--reranker-model",
        type=str,
        default="bge-reranker-base",
        help="é‡æ’åºæ¨¡å‹åç§°",
    )
    parser.add_argument("--no-rerank", action="store_true", help="ç¦ç”¨é‡æ’åº")

    args = parser.parse_args()

    # é»˜è®¤è·¯å¾„
    corpusFile = args.corpus or os.path.join(
        config.PROCESSED_DIR, "retrieval", "corpus.jsonl"
    )
    bm25IndexFile = args.bm25_index or os.path.join(
        config.PROCESSED_DIR, "retrieval", "bm25plus_index.pkl"
    )
    vectorIndexFile = args.vector_index or os.path.join(
        config.PROCESSED_DIR, "retrieval", "vector_index.faiss"
    )
    vectorEmbeddingFile = args.vector_embedding or os.path.join(
        config.PROCESSED_DIR, "retrieval", "vector_embeddings.npz"
    )

    print("=" * 80)
    print("ğŸ” å¸¦é‡æ’åºçš„æ£€ç´¢")
    print("=" * 80)
    print(f"ğŸ“‚ è¯­æ–™æ–‡ä»¶ï¼š{corpusFile}")
    print(f"ğŸ“‚ BM25 ç´¢å¼•ï¼š{bm25IndexFile}")
    print(f"ğŸ“‚ å‘é‡ç´¢å¼•ï¼š{vectorIndexFile}")
    print(f"ğŸ¤– æ£€ç´¢æ¨¡å‹ï¼š{args.model}")
    print(f"ğŸ¤– é‡æ’åºæ¨¡å‹ï¼š{args.reranker_model}")
    print(f"ğŸ“ˆ å¬å›æ•°é‡ï¼š{args.recall_topk}")
    print(f"ğŸ”€ é‡æ’åºï¼š{'ç¦ç”¨' if args.no_rerank else 'å¯ç”¨'}")
    print()

    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = RerankerRetriever(
        corpusFile,
        bm25IndexFile,
        vectorIndexFile,
        vectorEmbeddingFile,
        args.model,
        args.reranker_model,
    )

    # æ‰§è¡ŒæŸ¥è¯¢
    if args.query:
        results = retriever.search(
            args.query, args.topk, args.recall_topk, not args.no_rerank
        )
        printResults(args.query, results)

        if args.output:
            saveResults({args.query: results}, args.output)

    elif args.query_file:
        print(f"ğŸ“‚ åŠ è½½æŸ¥è¯¢ï¼š{args.query_file}")
        queries = loadQueriesFromFile(args.query_file)
        print(f"âœ… å·²åŠ è½½ {len(queries)} ä¸ªæŸ¥è¯¢\n")

        results = retriever.batchSearch(
            queries, args.topk, args.recall_topk, not args.no_rerank
        )

        for query, queryResults in results.items():
            printResults(query, queryResults)

        if args.output:
            saveResults(results, args.output)
        else:
            defaultOutput = os.path.join(
                config.PROJECT_ROOT, "outputs", "reranker_results.json"
            )
            saveResults(results, defaultOutput)

    else:
        print("âš ï¸  è¯·æä¾›æŸ¥è¯¢å‚æ•°")
        parser.print_help()


if __name__ == "__main__":
    main()
